{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Input, Flatten, LeakyReLU, ReLU, Conv2D, MaxPooling2D, UpSampling2D, Conv2DTranspose, concatenate, Activation\n",
    "# from tensorflow.keras.utils import plot_model\n",
    "# from tensorflow.keras.backend import clear_session\n",
    "# from tensorflow.keras.optimizers import Adam, RMSprop , SGD\n",
    "from tensorflow.keras import Sequential, Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "# from tensorflow.keras.regularizers import L2\n",
    "# from tensorflow.keras import metrics\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "import keras_tuner as kt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from os.path import join\n",
    "from os import listdir\n",
    "from shutil import copy\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>pH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>close_seg\\6\\6K--22-_jpg.rf.663142c881758efb4de...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>close_seg\\6\\6k--75-_jpg.rf.42aa04547265d5890c7...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>close_seg\\6\\6F--23-_jpg.rf.338da0e01de039e7b73...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>close_seg\\6\\6F--44-_jpg.rf.1521f3dad55c9c68fd2...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>close_seg\\6\\6k--13-_jpg.rf.47db8c03884b63f6b6f...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  pH\n",
       "0  close_seg\\6\\6K--22-_jpg.rf.663142c881758efb4de...   6\n",
       "1  close_seg\\6\\6k--75-_jpg.rf.42aa04547265d5890c7...   6\n",
       "2  close_seg\\6\\6F--23-_jpg.rf.338da0e01de039e7b73...   6\n",
       "3  close_seg\\6\\6F--44-_jpg.rf.1521f3dad55c9c68fd2...   6\n",
       "4  close_seg\\6\\6k--13-_jpg.rf.47db8c03884b63f6b6f...   6"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"df//train_df.csv\")\n",
    "val_df = pd.read_csv(\"df//val_df.csv\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(listdir(\"jpgData//6\")))\n",
    "# print(len(listdir(\"jpgData//7\")))\n",
    "# print(len(listdir(\"jpgData//8\")))\n",
    "# print(len(listdir(\"jpgData//9\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_col = \"path\"\n",
    "y_col = \"pH\"\n",
    "batch_size = 32\n",
    "epochs = 1024\n",
    "lr = 1e-5\n",
    "image_size = (32,32)\n",
    "channels = 3\n",
    "shuffle = True\n",
    "class_mode =\"raw\"\n",
    "color_mode = \"rgb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 512 validated image filenames.\n",
      "Found 131 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                    #  width_shift_range = 0.1,\n",
    "                                    #  height_shift_range = 0.1, \n",
    "                                    #  zoom_range = 0.2,\n",
    "                                    #  shear_range = 0.5,\n",
    "                                     horizontal_flip = True,\n",
    "                                     vertical_flip = True,\n",
    "                                     channel_shift_range = 64.0,\n",
    "                                    #  brightness_range = (0.3,1.0),\n",
    "                                    #  rotation_range = 15,\n",
    "                                     )\n",
    "train_generator = train_datagen.flow_from_dataframe(dataframe=train_df,\n",
    "                                              x_col=x_col, y_col=y_col, has_ext=True, \n",
    "                                              class_mode=class_mode, target_size=image_size, \n",
    "                                              batch_size=batch_size, color_mode = color_mode,\n",
    "                                              shuffle = shuffle)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_generator = val_datagen.flow_from_dataframe(dataframe=val_df,\n",
    "                                              x_col=x_col, y_col=y_col, has_ext=True, \n",
    "                                              class_mode=class_mode, target_size=image_size, \n",
    "                                              batch_size=batch_size,  color_mode = color_mode,\n",
    "                                              shuffle = shuffle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Design Alternatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design A: Nested U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Convolutional Block\n",
    "def conv_block(inputs, num_filters):\n",
    "\t# Applying the sequence of Convolutional, Batch Normalization\n",
    "\t# and Activation Layers to the input tensor\n",
    "\tx = Sequential([\n",
    "\t\t# Convolutional Layer\n",
    "\t\tConv2D(num_filters, 1, padding='same'),\n",
    "\t\t# Batch Normalization Layer\n",
    "\t\tBatchNormalization(),\n",
    "\t\t# Activation Layer\n",
    "\t\tReLU(),\n",
    "\t\t# Convolutional Layer\n",
    "\t\tConv2D(num_filters, 1, padding='same'),\n",
    "\t\t# Batch Normalization Layer\n",
    "\t\tBatchNormalization(),\n",
    "\t\t# Activation Layer\n",
    "\t\tReLU()\n",
    "\t])(inputs)\n",
    "\n",
    "\t# Returning the output of the Convolutional Block\n",
    "\treturn x\n",
    "\n",
    "# Defining the Unet++ Model\n",
    "def unet_plus_plus_model(input_shape=(image_size[0], image_size[1], channels), num_classes=1, deep_supervision=True):\n",
    "\tinputs = Input(shape=input_shape)\n",
    "\n",
    "\t# Encoding Path\n",
    "\tx_00 = conv_block(inputs, 64)\n",
    "\tx_10 = conv_block(MaxPooling2D()(x_00), 128)\n",
    "\tx_20 = conv_block(MaxPooling2D()(x_10), 256)\n",
    "\tx_30 = conv_block(MaxPooling2D()(x_20), 512)\n",
    "\tx_40 = conv_block(MaxPooling2D()(x_30), 1024)\n",
    "\n",
    "\t# Nested Decoding Path\n",
    "\tx_01 = conv_block(concatenate(\n",
    "\t\t[x_00, UpSampling2D()(x_10)]), 64)\n",
    "\tx_11 = conv_block(concatenate(\n",
    "\t\t[x_10, UpSampling2D()(x_20)]), 128)\n",
    "\tx_21 = conv_block(concatenate(\n",
    "\t\t[x_20, UpSampling2D()(x_30)]), 256)\n",
    "\tx_31 = conv_block(concatenate(\n",
    "\t\t[x_30, UpSampling2D()(x_40)]), 512)\n",
    "\n",
    "\tx_02 = conv_block(concatenate(\n",
    "\t\t[x_00, x_01, UpSampling2D()(x_11)]), 64)\n",
    "\tx_12 = conv_block(concatenate(\n",
    "\t\t[x_10, x_11, UpSampling2D()(x_21)]), 128)\n",
    "\tx_22 = conv_block(concatenate(\n",
    "\t\t[x_20, x_21, UpSampling2D()(x_31)]), 256)\n",
    "\n",
    "\tx_03 = conv_block(concatenate(\n",
    "\t\t[x_00, x_01, x_02, UpSampling2D()(x_12)]), 64)\n",
    "\tx_13 = conv_block(concatenate(\n",
    "\t\t[x_10, x_11, x_12, UpSampling2D()(x_22)]), 128)\n",
    "\n",
    "\tx_04 = conv_block(concatenate(\n",
    "\t\t[x_00, x_01, x_02, x_03, UpSampling2D()(x_13)]), 64)\n",
    "\n",
    "\t# Deep Supervision Path\n",
    "\t# If deep supervision is enabled, then the model will output the segmentation maps\n",
    "\t# at each stage of the decoding path\n",
    "\tif deep_supervision:\n",
    "\t\toutputs = [\n",
    "\t\t\tConv2D(num_classes, 1)(x_01),\n",
    "\t\t\tConv2D(num_classes, 1)(x_02),\n",
    "\t\t\tConv2D(num_classes, 1)(x_03),\n",
    "\t\t\tConv2D(num_classes, 1)(x_04)\n",
    "\t\t]\n",
    "\t\t# Concatenating the segmentation maps\n",
    "\t\toutputs = concatenate(outputs, axis=0)\n",
    "\n",
    "\t# If deep supervision is disabled, then the model will output the final segmentation map\n",
    "\t# which is the segmentation map at the end of the decoding path\n",
    "\telse:\n",
    "\t\tflatten  = layers.Flatten()(x_04)\n",
    "\t\tdense = Dense(1024, activation='relu')(flatten)\n",
    "\t\t# dense = Dense(512, activation='relu')(dense)\n",
    "\t\toutputs = Dense(1)(dense)\n",
    "\n",
    "\t# Creating the model\n",
    "\tmodel = tf.keras.Model(\n",
    "\t\tinputs=inputs, outputs=outputs, name='Unet_plus_plus')\n",
    "\n",
    "\t# Returning the model\n",
    "\treturn model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Unet_plus_plus\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " sequential (Sequential)        (None, 32, 32, 64)   4928        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 16, 16, 64)   0           ['sequential[0][0]']             \n",
      "                                                                                                  \n",
      " sequential_1 (Sequential)      (None, 16, 16, 128)  25856       ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 8, 8, 128)   0           ['sequential_1[0][0]']           \n",
      "                                                                                                  \n",
      " sequential_2 (Sequential)      (None, 8, 8, 256)    100864      ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 4, 4, 256)   0           ['sequential_2[0][0]']           \n",
      "                                                                                                  \n",
      " sequential_3 (Sequential)      (None, 4, 4, 512)    398336      ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 2, 2, 512)   0           ['sequential_3[0][0]']           \n",
      "                                                                                                  \n",
      " sequential_4 (Sequential)      (None, 2, 2, 1024)   1583104     ['max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " up_sampling2d_3 (UpSampling2D)  (None, 4, 4, 1024)  0           ['sequential_4[0][0]']           \n",
      "                                                                                                  \n",
      " up_sampling2d_2 (UpSampling2D)  (None, 8, 8, 512)   0           ['sequential_3[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 4, 4, 1536)   0           ['sequential_3[0][0]',           \n",
      "                                                                  'up_sampling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " up_sampling2d_1 (UpSampling2D)  (None, 16, 16, 256)  0          ['sequential_2[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 8, 8, 768)    0           ['sequential_2[0][0]',           \n",
      "                                                                  'up_sampling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " sequential_8 (Sequential)      (None, 4, 4, 512)    1053696     ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " up_sampling2d (UpSampling2D)   (None, 32, 32, 128)  0           ['sequential_1[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 16, 16, 384)  0           ['sequential_1[0][0]',           \n",
      "                                                                  'up_sampling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " sequential_7 (Sequential)      (None, 8, 8, 256)    264704      ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " up_sampling2d_6 (UpSampling2D)  (None, 8, 8, 512)   0           ['sequential_8[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 32, 32, 192)  0           ['sequential[0][0]',             \n",
      "                                                                  'up_sampling2d[0][0]']          \n",
      "                                                                                                  \n",
      " sequential_6 (Sequential)      (None, 16, 16, 128)  66816       ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " up_sampling2d_5 (UpSampling2D)  (None, 16, 16, 256)  0          ['sequential_7[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 8, 8, 1024)   0           ['sequential_2[0][0]',           \n",
      "                                                                  'sequential_7[0][0]',           \n",
      "                                                                  'up_sampling2d_6[0][0]']        \n",
      "                                                                                                  \n",
      " sequential_5 (Sequential)      (None, 32, 32, 64)   17024       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " up_sampling2d_4 (UpSampling2D)  (None, 32, 32, 128)  0          ['sequential_6[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 16, 16, 512)  0           ['sequential_1[0][0]',           \n",
      "                                                                  'sequential_6[0][0]',           \n",
      "                                                                  'up_sampling2d_5[0][0]']        \n",
      "                                                                                                  \n",
      " sequential_11 (Sequential)     (None, 8, 8, 256)    330240      ['concatenate_6[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 32, 32, 256)  0           ['sequential[0][0]',             \n",
      "                                                                  'sequential_5[0][0]',           \n",
      "                                                                  'up_sampling2d_4[0][0]']        \n",
      "                                                                                                  \n",
      " sequential_10 (Sequential)     (None, 16, 16, 128)  83200       ['concatenate_5[0][0]']          \n",
      "                                                                                                  \n",
      " up_sampling2d_8 (UpSampling2D)  (None, 16, 16, 256)  0          ['sequential_11[0][0]']          \n",
      "                                                                                                  \n",
      " sequential_9 (Sequential)      (None, 32, 32, 64)   21120       ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      " up_sampling2d_7 (UpSampling2D)  (None, 32, 32, 128)  0          ['sequential_10[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_8 (Concatenate)    (None, 16, 16, 640)  0           ['sequential_1[0][0]',           \n",
      "                                                                  'sequential_6[0][0]',           \n",
      "                                                                  'sequential_10[0][0]',          \n",
      "                                                                  'up_sampling2d_8[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 32, 32, 320)  0           ['sequential[0][0]',             \n",
      "                                                                  'sequential_5[0][0]',           \n",
      "                                                                  'sequential_9[0][0]',           \n",
      "                                                                  'up_sampling2d_7[0][0]']        \n",
      "                                                                                                  \n",
      " sequential_13 (Sequential)     (None, 16, 16, 128)  99584       ['concatenate_8[0][0]']          \n",
      "                                                                                                  \n",
      " sequential_12 (Sequential)     (None, 32, 32, 64)   25216       ['concatenate_7[0][0]']          \n",
      "                                                                                                  \n",
      " up_sampling2d_9 (UpSampling2D)  (None, 32, 32, 128)  0          ['sequential_13[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_9 (Concatenate)    (None, 32, 32, 384)  0           ['sequential[0][0]',             \n",
      "                                                                  'sequential_5[0][0]',           \n",
      "                                                                  'sequential_9[0][0]',           \n",
      "                                                                  'sequential_12[0][0]',          \n",
      "                                                                  'up_sampling2d_9[0][0]']        \n",
      "                                                                                                  \n",
      " sequential_14 (Sequential)     (None, 32, 32, 64)   29312       ['concatenate_9[0][0]']          \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 65536)        0           ['sequential_14[0][0]']          \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1024)         67109888    ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1)            1025        ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 71,214,913\n",
      "Trainable params: 71,200,321\n",
      "Non-trainable params: 14,592\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Creating the model\n",
    "modelA = unet_plus_plus_model(input_shape=(\n",
    "\timage_size[0], image_size[1], channels), deep_supervision=False)\n",
    "modelA.compile(optimizer=tf.keras.optimizers.Adam(lr), loss='mean_squared_error', metrics=['mae'])\n",
    "modelA.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# historyA = modelA.fit(train_generator, epochs=10, validation_data=val_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Graphing Result of training\n",
    "# plt.figure(figsize=(15,4))\n",
    "\n",
    "# plt.subplot(121)\n",
    "# plt.plot(historyA.history['mae'], color ='r')\n",
    "# plt.plot(historyA.history['val_mae'])\n",
    "# plt.title('mae')\n",
    "# plt.legend(['train','validation'])\n",
    "# plt.xlabel('epoch')\n",
    "# plt.ylabel('mae')\n",
    "\n",
    "# plt.subplot(122)\n",
    "# plt.plot(historyA.history['loss'], color ='r')\n",
    "# plt.plot(historyA.history['val_loss'])\n",
    "# plt.title('loss')\n",
    "# plt.legend(['train','validation'])\n",
    "# plt.xlabel('epoch')\n",
    "# plt.ylabel('mean squared error')\n",
    "\n",
    "# # displaying the figure\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Best model saved\n",
    "# train_loss = historyA.history['loss']\n",
    "# train_mae = historyA.history['mae']\n",
    "# val_loss = historyA.history['val_loss']\n",
    "# val_mae = historyA.history['val_mae']\n",
    "\n",
    "# best_epoch = np.argmin(np.array(val_loss))\n",
    "\n",
    "# print(\"Best Epoch: \", best_epoch)\n",
    "# print(\"Final Train Loss: {:.4f}\".format(train_loss[best_epoch]))\n",
    "# print(\"Final Validation Loss: {:.4f}\".format(val_loss[best_epoch]))\n",
    "# print(\"Final Train MAE: {:.2f}\".format(train_mae[best_epoch]*100))\n",
    "# print(\"Final Test MAE: {:.2f}\".format(val_mae[best_epoch]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design B: SegNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segnet(input_shape):\n",
    "\n",
    "    # Encoding layer\n",
    "    img_input = Input(shape= input_shape)\n",
    "    x = Conv2D(64, (3, 3), padding='same', name='conv1',strides= (1,1))(img_input)\n",
    "    x = BatchNormalization(name='bn1')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(64, (3, 3), padding='same', name='conv2')(x)\n",
    "    x = BatchNormalization(name='bn2')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D()(x)\n",
    "    \n",
    "    x = Conv2D(128, (3, 3), padding='same', name='conv3')(x)\n",
    "    x = BatchNormalization(name='bn3')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(128, (3, 3), padding='same', name='conv4')(x)\n",
    "    x = BatchNormalization(name='bn4')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D()(x)\n",
    "\n",
    "    x = Conv2D(256, (3, 3), padding='same', name='conv5')(x)\n",
    "    x = BatchNormalization(name='bn5')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(256, (3, 3), padding='same', name='conv6')(x)\n",
    "    x = BatchNormalization(name='bn6')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(256, (3, 3), padding='same', name='conv7')(x)\n",
    "    x = BatchNormalization(name='bn7')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D()(x)\n",
    "\n",
    "    x = Conv2D(512, (3, 3), padding='same', name='conv8')(x)\n",
    "    x = BatchNormalization(name='bn8')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(512, (3, 3), padding='same', name='conv9')(x)\n",
    "    x = BatchNormalization(name='bn9')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(512, (3, 3), padding='same', name='conv10')(x)\n",
    "    x = BatchNormalization(name='bn10')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D()(x)\n",
    "    \n",
    "    x = Conv2D(512, (3, 3), padding='same', name='conv11')(x)\n",
    "    x = BatchNormalization(name='bn11')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(512, (3, 3), padding='same', name='conv12')(x)\n",
    "    x = BatchNormalization(name='bn12')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(512, (3, 3), padding='same', name='conv13')(x)\n",
    "    x = BatchNormalization(name='bn13')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D()(x)\n",
    "\n",
    "    x = Dense(1024, activation = 'relu', name='fc1')(x)\n",
    "    x = Dense(1024, activation = 'relu', name='fc2')(x)\n",
    "    # Decoding Layer \n",
    "    x = UpSampling2D()(x)\n",
    "    x = Conv2DTranspose(512, (3, 3), padding='same', name='deconv1')(x)\n",
    "    x = BatchNormalization(name='bn14')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2DTranspose(512, (3, 3), padding='same', name='deconv2')(x)\n",
    "    x = BatchNormalization(name='bn15')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2DTranspose(512, (3, 3), padding='same', name='deconv3')(x)\n",
    "    x = BatchNormalization(name='bn16')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = UpSampling2D()(x)\n",
    "    x = Conv2DTranspose(512, (3, 3), padding='same', name='deconv4')(x)\n",
    "    x = BatchNormalization(name='bn17')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2DTranspose(512, (3, 3), padding='same', name='deconv5')(x)\n",
    "    x = BatchNormalization(name='bn18')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2DTranspose(256, (3, 3), padding='same', name='deconv6')(x)\n",
    "    x = BatchNormalization(name='bn19')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = UpSampling2D()(x)\n",
    "    x = Conv2DTranspose(256, (3, 3), padding='same', name='deconv7')(x)\n",
    "    x = BatchNormalization(name='bn20')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2DTranspose(256, (3, 3), padding='same', name='deconv8')(x)\n",
    "    x = BatchNormalization(name='bn21')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2DTranspose(128, (3, 3), padding='same', name='deconv9')(x)\n",
    "    x = BatchNormalization(name='bn22')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = UpSampling2D()(x)\n",
    "    x = Conv2DTranspose(128, (3, 3), padding='same', name='deconv10')(x)\n",
    "    x = BatchNormalization(name='bn23')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2DTranspose(64, (3, 3), padding='same', name='deconv11')(x)\n",
    "    x = BatchNormalization(name='bn24')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = UpSampling2D()(x)\n",
    "    x = Conv2DTranspose(64, (3, 3), padding='same', name='deconv12')(x)\n",
    "    x = BatchNormalization(name='bn25')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2DTranspose(1, (3, 3), padding='same', name='deconv13')(x)\n",
    "    x = BatchNormalization(name='bn26')(x)\n",
    "    x = Activation('sigmoid')(x)\n",
    "    # pred = Reshape((192,256))(x)\n",
    "    x = Flatten()(x)\n",
    "    x=Dense(1024, activation='relu')(x)\n",
    "    otuput=Dense(1, activation='linear')(x)\n",
    "    \n",
    "    model = Model(inputs=img_input, outputs=otuput)\n",
    "    \n",
    "    model.compile(optimizer= tf.keras.optimizers.Adam(lr=lr), loss= [\"mse\"]\n",
    "                  , metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " conv1 (Conv2D)              (None, 32, 32, 64)        1792      \n",
      "                                                                 \n",
      " bn1 (BatchNormalization)    (None, 32, 32, 64)        256       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " conv2 (Conv2D)              (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " bn2 (BatchNormalization)    (None, 32, 32, 64)        256       \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 16, 16, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv3 (Conv2D)              (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " bn3 (BatchNormalization)    (None, 16, 16, 128)       512       \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " conv4 (Conv2D)              (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " bn4 (BatchNormalization)    (None, 16, 16, 128)       512       \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 8, 8, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv5 (Conv2D)              (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " bn5 (BatchNormalization)    (None, 8, 8, 256)         1024      \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " conv6 (Conv2D)              (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " bn6 (BatchNormalization)    (None, 8, 8, 256)         1024      \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " conv7 (Conv2D)              (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " bn7 (BatchNormalization)    (None, 8, 8, 256)         1024      \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 4, 4, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv8 (Conv2D)              (None, 4, 4, 512)         1180160   \n",
      "                                                                 \n",
      " bn8 (BatchNormalization)    (None, 4, 4, 512)         2048      \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " conv9 (Conv2D)              (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " bn9 (BatchNormalization)    (None, 4, 4, 512)         2048      \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " conv10 (Conv2D)             (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " bn10 (BatchNormalization)   (None, 4, 4, 512)         2048      \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 2, 2, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv11 (Conv2D)             (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " bn11 (BatchNormalization)   (None, 2, 2, 512)         2048      \n",
      "                                                                 \n",
      " activation_10 (Activation)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " conv12 (Conv2D)             (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " bn12 (BatchNormalization)   (None, 2, 2, 512)         2048      \n",
      "                                                                 \n",
      " activation_11 (Activation)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " conv13 (Conv2D)             (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " bn13 (BatchNormalization)   (None, 2, 2, 512)         2048      \n",
      "                                                                 \n",
      " activation_12 (Activation)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 1, 1, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 1, 1, 1024)        525312    \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 1, 1, 1024)        1049600   \n",
      "                                                                 \n",
      " up_sampling2d_10 (UpSamplin  (None, 2, 2, 1024)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " deconv1 (Conv2DTranspose)   (None, 2, 2, 512)         4719104   \n",
      "                                                                 \n",
      " bn14 (BatchNormalization)   (None, 2, 2, 512)         2048      \n",
      "                                                                 \n",
      " activation_13 (Activation)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " deconv2 (Conv2DTranspose)   (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " bn15 (BatchNormalization)   (None, 2, 2, 512)         2048      \n",
      "                                                                 \n",
      " activation_14 (Activation)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " deconv3 (Conv2DTranspose)   (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " bn16 (BatchNormalization)   (None, 2, 2, 512)         2048      \n",
      "                                                                 \n",
      " activation_15 (Activation)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " up_sampling2d_11 (UpSamplin  (None, 4, 4, 512)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " deconv4 (Conv2DTranspose)   (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " bn17 (BatchNormalization)   (None, 4, 4, 512)         2048      \n",
      "                                                                 \n",
      " activation_16 (Activation)  (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " deconv5 (Conv2DTranspose)   (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " bn18 (BatchNormalization)   (None, 4, 4, 512)         2048      \n",
      "                                                                 \n",
      " activation_17 (Activation)  (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " deconv6 (Conv2DTranspose)   (None, 4, 4, 256)         1179904   \n",
      "                                                                 \n",
      " bn19 (BatchNormalization)   (None, 4, 4, 256)         1024      \n",
      "                                                                 \n",
      " activation_18 (Activation)  (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " up_sampling2d_12 (UpSamplin  (None, 8, 8, 256)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " deconv7 (Conv2DTranspose)   (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " bn20 (BatchNormalization)   (None, 8, 8, 256)         1024      \n",
      "                                                                 \n",
      " activation_19 (Activation)  (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " deconv8 (Conv2DTranspose)   (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " bn21 (BatchNormalization)   (None, 8, 8, 256)         1024      \n",
      "                                                                 \n",
      " activation_20 (Activation)  (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " deconv9 (Conv2DTranspose)   (None, 8, 8, 128)         295040    \n",
      "                                                                 \n",
      " bn22 (BatchNormalization)   (None, 8, 8, 128)         512       \n",
      "                                                                 \n",
      " activation_21 (Activation)  (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " up_sampling2d_13 (UpSamplin  (None, 16, 16, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " deconv10 (Conv2DTranspose)  (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " bn23 (BatchNormalization)   (None, 16, 16, 128)       512       \n",
      "                                                                 \n",
      " activation_22 (Activation)  (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " deconv11 (Conv2DTranspose)  (None, 16, 16, 64)        73792     \n",
      "                                                                 \n",
      " bn24 (BatchNormalization)   (None, 16, 16, 64)        256       \n",
      "                                                                 \n",
      " activation_23 (Activation)  (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " up_sampling2d_14 (UpSamplin  (None, 32, 32, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " deconv12 (Conv2DTranspose)  (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " bn25 (BatchNormalization)   (None, 32, 32, 64)        256       \n",
      "                                                                 \n",
      " activation_24 (Activation)  (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " deconv13 (Conv2DTranspose)  (None, 32, 32, 1)         577       \n",
      "                                                                 \n",
      " bn26 (BatchNormalization)   (None, 32, 32, 1)         4         \n",
      "                                                                 \n",
      " activation_25 (Activation)  (None, 32, 32, 1)         0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 1025      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34,444,294\n",
      "Trainable params: 34,428,420\n",
      "Non-trainable params: 15,874\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "modelB = segnet(input_shape=image_size+(3,))\n",
    "modelB.summary()\n",
    "\n",
    "\n",
    "# model.save(savename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist = modelB.fit(train_generator, epochs= 10, validation_data= val_generator, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelB = segnet(input_shape=image_size+(3,))\n",
    "# modelB.compile(optimizer=tf.keras.optimizers.Adam(lr), loss='mse', metrics=['mae'])\n",
    "# modelB.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## MANUFACTURABILITY: TRAINING TIME\n",
    "# import time \n",
    "# start = time.time()\n",
    "# historyB = modelB.fit(train_generator, epochs=10, validation_data=val_generator, verbose=0)\n",
    "# stop = time.time()\n",
    "# print(f\"Training time: {stop - start}s\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Graphing Result of training\n",
    "# plt.figure(figsize=(15,4))\n",
    "\n",
    "# plt.subplot(121)\n",
    "# plt.plot(historyB.history['mae'], color ='r')\n",
    "# plt.plot(historyB.history['val_mae'])\n",
    "# plt.title('mae')\n",
    "# plt.legend(['train','validation'])\n",
    "# plt.xlabel('epoch')\n",
    "# plt.ylabel('mae')\n",
    "\n",
    "# plt.subplot(122)\n",
    "# plt.plot(historyB.history['loss'], color ='r')\n",
    "# plt.plot(historyB.history['val_loss'])\n",
    "# plt.title('loss')\n",
    "# plt.legend(['train','validation'])\n",
    "# plt.xlabel('epoch')\n",
    "# plt.ylabel('mean squared error')\n",
    "\n",
    "# # displaying the figure\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Best model saved\n",
    "# train_loss = historyB.history['loss']\n",
    "# train_mae = historyB.history['mae']\n",
    "# val_loss = historyB.history['val_loss']\n",
    "# val_mae = historyB.history['val_mae']\n",
    "\n",
    "# best_epoch = np.argmin(np.array(val_loss))\n",
    "\n",
    "# print(\"Best Epoch: \", best_epoch)\n",
    "# print(\"Final Train Loss: {:.4f}\".format(train_loss[best_epoch]))\n",
    "# print(\"Final Validation Loss: {:.4f}\".format(val_loss[best_epoch]))\n",
    "# print(\"Final Train MAE: {:.2f}\".format(train_mae[best_epoch]*100))\n",
    "# print(\"Final Test MAE: {:.2f}\".format(val_mae[best_epoch]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 8, 7, 9, 8, 9, 9, 6, 9, 6, 7, 9, 8, 7, 8, 6, 7, 6, 9, 9, 7, 8,\n",
       "       6, 7, 8, 6, 9, 9, 7, 7, 6, 6], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator[1][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design C: DeepLabv3+\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 38, 38, 3)    0           ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 16, 16, 64)   9472        ['conv1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, 16, 16, 64)   256         ['conv1_conv[0][0]']             \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)        (None, 16, 16, 64)   0           ['conv1_bn[0][0]']               \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 18, 18, 64)   0           ['conv1_relu[0][0]']             \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 8, 8, 64)     0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 8, 8, 64)     4160        ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 8, 8, 64)     36928       ['conv2_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 8, 8, 256)    16640       ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 8, 8, 256)    16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)         (None, 8, 8, 256)    0           ['conv2_block1_0_bn[0][0]',      \n",
      "                                                                  'conv2_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activation)  (None, 8, 8, 256)    0           ['conv2_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 8, 8, 64)     16448       ['conv2_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 8, 8, 64)     36928       ['conv2_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 8, 8, 256)    16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_add (Add)         (None, 8, 8, 256)    0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activation)  (None, 8, 8, 256)    0           ['conv2_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 8, 8, 64)     16448       ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 8, 8, 64)     36928       ['conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 8, 8, 256)    16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)         (None, 8, 8, 256)    0           ['conv2_block2_out[0][0]',       \n",
      "                                                                  'conv2_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activation)  (None, 8, 8, 256)    0           ['conv2_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 4, 4, 128)    32896       ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 4, 4, 512)    131584      ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)         (None, 4, 4, 512)    0           ['conv3_block1_0_bn[0][0]',      \n",
      "                                                                  'conv3_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 4, 4, 128)    65664       ['conv3_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)         (None, 4, 4, 512)    0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 4, 4, 128)    65664       ['conv3_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)         (None, 4, 4, 512)    0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 4, 4, 128)    65664       ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)         (None, 4, 4, 512)    0           ['conv3_block3_out[0][0]',       \n",
      "                                                                  'conv3_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 2, 2, 256)    131328      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 2, 2, 1024)   525312      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block1_0_bn[0][0]',      \n",
      "                                                                  'conv4_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block1_out[0][0]',       \n",
      "                                                                  'conv4_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block2_out[0][0]',       \n",
      "                                                                  'conv4_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block3_out[0][0]',       \n",
      "                                                                  'conv4_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block5_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block4_out[0][0]',       \n",
      "                                                                  'conv4_block5_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block5_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " average_pooling2d_2 (AveragePo  (None, 1, 1, 256)   0           ['conv4_block6_2_relu[0][0]']    \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 1, 1, 256)    65792       ['average_pooling2d_2[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 1, 1, 256)   1024        ['conv2d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 2, 2, 256)    65536       ['conv4_block6_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 2, 2, 256)    589824      ['conv4_block6_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 2, 2, 256)    589824      ['conv4_block6_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 2, 2, 256)    589824      ['conv4_block6_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " tf.nn.relu_18 (TFOpLambda)     (None, 1, 1, 256)    0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_20[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_21[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_22[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " up_sampling2d_6 (UpSampling2D)  (None, 2, 2, 256)   0           ['tf.nn.relu_18[0][0]']          \n",
      "                                                                                                  \n",
      " tf.nn.relu_19 (TFOpLambda)     (None, 2, 2, 256)    0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " tf.nn.relu_20 (TFOpLambda)     (None, 2, 2, 256)    0           ['batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " tf.nn.relu_21 (TFOpLambda)     (None, 2, 2, 256)    0           ['batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " tf.nn.relu_22 (TFOpLambda)     (None, 2, 2, 256)    0           ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 2, 2, 1280)   0           ['up_sampling2d_6[0][0]',        \n",
      "                                                                  'tf.nn.relu_19[0][0]',          \n",
      "                                                                  'tf.nn.relu_20[0][0]',          \n",
      "                                                                  'tf.nn.relu_21[0][0]',          \n",
      "                                                                  'tf.nn.relu_22[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 2, 2, 256)    327680      ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_23[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 8, 8, 48)     3072        ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " tf.nn.relu_23 (TFOpLambda)     (None, 2, 2, 256)    0           ['batch_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 8, 8, 48)    192         ['conv2d_24[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " up_sampling2d_7 (UpSampling2D)  (None, 8, 8, 256)   0           ['tf.nn.relu_23[0][0]']          \n",
      "                                                                                                  \n",
      " tf.nn.relu_24 (TFOpLambda)     (None, 8, 8, 48)     0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 8, 8, 304)    0           ['up_sampling2d_7[0][0]',        \n",
      "                                                                  'tf.nn.relu_24[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 8, 8, 256)    700416      ['concatenate_5[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 8, 8, 256)   1024        ['conv2d_25[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.nn.relu_25 (TFOpLambda)     (None, 8, 8, 256)    0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 8, 8, 256)    589824      ['tf.nn.relu_25[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 8, 8, 256)   1024        ['conv2d_26[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.nn.relu_26 (TFOpLambda)     (None, 8, 8, 256)    0           ['batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " up_sampling2d_8 (UpSampling2D)  (None, 32, 32, 256)  0          ['tf.nn.relu_26[0][0]']          \n",
      "                                                                                                  \n",
      " global_average_pooling2d_2 (Gl  (None, 256)         0           ['up_sampling2d_8[0][0]']        \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 1024)         263168      ['global_average_pooling2d_2[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 1)            1025        ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 12,116,289\n",
      "Trainable params: 12,083,553\n",
      "Non-trainable params: 32,736\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def convolution_block(\n",
    "    block_input,\n",
    "    num_filters=256,\n",
    "    kernel_size=3,\n",
    "    dilation_rate=1,\n",
    "    padding=\"same\",\n",
    "    use_bias=False,\n",
    "):\n",
    "    x = layers.Conv2D(\n",
    "        num_filters,\n",
    "        kernel_size=kernel_size,\n",
    "        dilation_rate=dilation_rate,\n",
    "        padding=\"same\",\n",
    "        use_bias=use_bias,\n",
    "        kernel_initializer=keras.initializers.HeNormal(),\n",
    "    )(block_input)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "def DilatedSpatialPyramidPooling(dspp_input):\n",
    "    dims = dspp_input.shape\n",
    "    x = layers.AveragePooling2D(pool_size=(dims[-3], dims[-2]))(dspp_input)\n",
    "    x = convolution_block(x, kernel_size=1, use_bias=True)\n",
    "    out_pool = layers.UpSampling2D(\n",
    "        size=(dims[-3] // x.shape[1], dims[-2] // x.shape[2]), interpolation=\"bilinear\",\n",
    "    )(x)\n",
    "\n",
    "    out_1 = convolution_block(dspp_input, kernel_size=1, dilation_rate=1)\n",
    "    out_6 = convolution_block(dspp_input, kernel_size=3, dilation_rate=6)\n",
    "    out_12 = convolution_block(dspp_input, kernel_size=3, dilation_rate=12)\n",
    "    out_18 = convolution_block(dspp_input, kernel_size=3, dilation_rate=18)\n",
    "\n",
    "    x = layers.Concatenate(axis=-1)([out_pool, out_1, out_6, out_12, out_18])\n",
    "    output = convolution_block(x, kernel_size=1)\n",
    "    return output\n",
    "\n",
    "def DeeplabV3Plus(image_size):\n",
    "    model_input = keras.Input(shape=(image_size, image_size, 3))\n",
    "    resnet50 = keras.applications.ResNet50(\n",
    "        weights=None, include_top=False, input_tensor=model_input\n",
    "    )\n",
    "    x = resnet50.get_layer(\"conv4_block6_2_relu\").output\n",
    "    x = DilatedSpatialPyramidPooling(x)\n",
    "\n",
    "    input_a = layers.UpSampling2D(\n",
    "        size=(image_size // 4 // x.shape[1], image_size // 4 // x.shape[2]),\n",
    "        interpolation=\"bilinear\",\n",
    "    )(x)\n",
    "    input_b = resnet50.get_layer(\"conv2_block3_2_relu\").output\n",
    "    input_b = convolution_block(input_b, num_filters=48, kernel_size=1)\n",
    "\n",
    "    x = layers.Concatenate(axis=-1)([input_a, input_b])\n",
    "    x = convolution_block(x)\n",
    "    x = convolution_block(x)\n",
    "    x = layers.UpSampling2D(\n",
    "        size=(image_size // x.shape[1], image_size // x.shape[2]),\n",
    "        interpolation=\"bilinear\",\n",
    "    )(x)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x= Dense(1024, activation=\"relu\",)(x)\n",
    "    model_output = layers.Dense(1, activation='linear')(x)\n",
    "    return keras.Model(inputs=model_input, outputs=model_output)\n",
    "\n",
    "\n",
    "modelC = DeeplabV3Plus(image_size=image_size[0])\n",
    "modelC.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelC.compile(optimizer=tf.keras.optimizers.Adam(lr), loss='mse', metrics=['mae'])\n",
    "\n",
    "# historyC = modelC.fit(train_generator, epochs=10, validation_data=val_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Graphing Result of training\n",
    "# plt.figure(figsize=(15,4))\n",
    "\n",
    "# plt.subplot(121)\n",
    "# plt.plot(historyC.history['mae'], color ='r')\n",
    "# plt.plot(historyC.history['val_mae'])\n",
    "# plt.title('mae')\n",
    "# plt.legend(['train','validation'])\n",
    "# plt.xlabel('epoch')\n",
    "# plt.ylabel('mae')\n",
    "\n",
    "# plt.subplot(122)\n",
    "# plt.plot(historyC.history['loss'], color ='r')\n",
    "# plt.plot(historyC.history['val_loss'])\n",
    "# plt.title('loss')\n",
    "# plt.legend(['train','validation'])\n",
    "# plt.xlabel('epoch')\n",
    "# plt.ylabel('mean squared error')\n",
    "\n",
    "# # displaying the figure\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Best model saved\n",
    "# train_loss = historyC.history['loss']\n",
    "# train_mae = historyC.history['mae']\n",
    "# val_loss = historyC.history['val_loss']\n",
    "# val_mae = historyC.history['val_mae']\n",
    "\n",
    "# best_epoch = np.argmin(np.array(val_loss))\n",
    "\n",
    "# print(\"Best Epoch: \", best_epoch)\n",
    "# print(\"Final Train Loss: {:.4f}\".format(train_loss[best_epoch]))\n",
    "# print(\"Final Validation Loss: {:.4f}\".format(val_loss[best_epoch]))\n",
    "# print(\"Final Train MAE: {:.2f}\".format(train_mae[best_epoch]*100))\n",
    "# print(\"Final Test MAE: {:.2f}\".format(val_mae[best_epoch]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of Designs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization of Designs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Convolutional Block\n",
    "def conv_block(inputs, num_filters):\n",
    "\t# Applying the sequence of Convolutional, Batch Normalization\n",
    "\t# and Activation Layers to the input tensor\n",
    "\tx = Sequential([\n",
    "\t\t# Convolutional Layer\n",
    "\t\tConv2D(num_filters, 1, padding='same'),\n",
    "\t\t# Batch Normalization Layer\n",
    "\t\tBatchNormalization(),\n",
    "\t\t# Activation Layer\n",
    "\t\tReLU(),\n",
    "\t\t# Convolutional Layer\n",
    "\t\tConv2D(num_filters, 1, padding='same'),\n",
    "\t\t# Batch Normalization Layer\n",
    "\t\tBatchNormalization(),\n",
    "\t\t# Activation Layer\n",
    "\t\tReLU()\n",
    "\t])(inputs)\n",
    "\n",
    "\t# Returning the output of the Convolutional Block\n",
    "\treturn x\n",
    "\n",
    "# Defining the Unet++ Model\n",
    "def unet_plus_plus_model(hp):\n",
    "\tinputs = Input(shape=(32,32,3))\n",
    "\thp_filters = hp.Choice('filters',values = [64,128,256])\n",
    "\t# Encoding Path\n",
    "\tx_00 = conv_block(inputs, hp_filters)\n",
    "\tx_10 = conv_block(MaxPooling2D()(x_00), hp_filters*2)\n",
    "\tx_20 = conv_block(MaxPooling2D()(x_10), hp_filters*4)\n",
    "\tx_30 = conv_block(MaxPooling2D()(x_20), hp_filters*8)\n",
    "\tx_40 = conv_block(MaxPooling2D()(x_30), hp_filters*16)\n",
    "\n",
    "\t# Nested Decoding Path\n",
    "\tx_01 = conv_block(concatenate(\n",
    "\t\t[x_00, UpSampling2D()(x_10)]), hp_filters)\n",
    "\tx_11 = conv_block(concatenate(\n",
    "\t\t[x_10, UpSampling2D()(x_20)]), hp_filters*2)\n",
    "\tx_21 = conv_block(concatenate(\n",
    "\t\t[x_20, UpSampling2D()(x_30)]), hp_filters*4)\n",
    "\tx_31 = conv_block(concatenate(\n",
    "\t\t[x_30, UpSampling2D()(x_40)]), hp_filters*8)\n",
    "\n",
    "\tx_02 = conv_block(concatenate(\n",
    "\t\t[x_00, x_01, UpSampling2D()(x_11)]), hp_filters)\n",
    "\tx_12 = conv_block(concatenate(\n",
    "\t\t[x_10, x_11, UpSampling2D()(x_21)]), hp_filters*2)\n",
    "\tx_22 = conv_block(concatenate(\n",
    "\t\t[x_20, x_21, UpSampling2D()(x_31)]), hp_filters*4)\n",
    "\n",
    "\tx_03 = conv_block(concatenate(\n",
    "\t\t[x_00, x_01, x_02, UpSampling2D()(x_12)]), hp_filters)\n",
    "\tx_13 = conv_block(concatenate(\n",
    "\t\t[x_10, x_11, x_12, UpSampling2D()(x_22)]), hp_filters*2)\n",
    "\n",
    "\tx_04 = conv_block(concatenate(\n",
    "\t\t[x_00, x_01, x_02, x_03, UpSampling2D()(x_13)]), hp_filters)\n",
    "\n",
    "\t# # Deep Supervision Path\n",
    "\t# # If deep supervision is enabled, then the model will output the segmentation maps\n",
    "\t# # at each stage of the decoding path\n",
    "\t# if deep_supervision:\n",
    "\t# \toutputs = [\n",
    "\t# \t\tConv2D(num_classes, 1)(x_01),\n",
    "\t# \t\tConv2D(num_classes, 1)(x_02),\n",
    "\t# \t\tConv2D(num_classes, 1)(x_03),\n",
    "\t# \t\tConv2D(num_classes, 1)(x_04)\n",
    "\t# \t]\n",
    "\t# \t# Concatenating the segmentation maps\n",
    "\t# \toutputs = concatenate(outputs, axis=0)\n",
    "\n",
    "\t# # If deep supervision is disabled, then the model will output the final segmentation map\n",
    "\t# # which is the segmentation map at the end of the decoding path\n",
    "\t# else:\n",
    "\tflatten  = layers.Flatten()(x_04)\n",
    "\thp_units = hp.Choice('units',values = [512,1024])\n",
    "\tdense = Dense(hp_units, activation='relu')(flatten)\n",
    "\tif hp.Boolean(\"2nd dense\"):\n",
    "\t\tdense = Dense(hp_units, activation='relu')(dense)\n",
    "\toutputs = Dense(1)(dense)\n",
    "\n",
    "\t# Creating the model\n",
    "\tmodel = tf.keras.Model(\n",
    "\t\tinputs=inputs, outputs=outputs, name='Unet_plus_plus')\n",
    "\t\n",
    "\thp_learning_rate = hp.Choice('learning_rate', values=[1e-3, 1e-4, 1e-5])\n",
    "\tmodel.compile(optimizer=tf.keras.optimizers.Adam(hp_learning_rate), loss='mean_squared_error', metrics=['mae'])\n",
    "\t# Returning the model\n",
    "\treturn model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1757.1242140707857"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## approximate number of cumulative epochs\n",
    "import math\n",
    "## max_epochs * (math.log(max_epochs, factor) ** 2)\n",
    "100 * (math.log(100, 3) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 02m 10s]\n",
      "val_loss: 1.33049476146698\n",
      "\n",
      "Best val_loss So Far: 0.9444683790206909\n",
      "Total elapsed time: 00h 25m 31s\n",
      "Model: \"Unet_plus_plus\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " sequential_15 (Sequential)     (None, 32, 32, 128)  18048       ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 16, 16, 128)  0          ['sequential_15[0][0]']          \n",
      "                                                                                                  \n",
      " sequential_16 (Sequential)     (None, 16, 16, 256)  100864      ['max_pooling2d_4[0][0]']        \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPooling2D)  (None, 8, 8, 256)   0           ['sequential_16[0][0]']          \n",
      "                                                                                                  \n",
      " sequential_17 (Sequential)     (None, 8, 8, 512)    398336      ['max_pooling2d_5[0][0]']        \n",
      "                                                                                                  \n",
      " max_pooling2d_6 (MaxPooling2D)  (None, 4, 4, 512)   0           ['sequential_17[0][0]']          \n",
      "                                                                                                  \n",
      " sequential_18 (Sequential)     (None, 4, 4, 1024)   1583104     ['max_pooling2d_6[0][0]']        \n",
      "                                                                                                  \n",
      " max_pooling2d_7 (MaxPooling2D)  (None, 2, 2, 1024)  0           ['sequential_18[0][0]']          \n",
      "                                                                                                  \n",
      " sequential_19 (Sequential)     (None, 2, 2, 2048)   6311936     ['max_pooling2d_7[0][0]']        \n",
      "                                                                                                  \n",
      " up_sampling2d_13 (UpSampling2D  (None, 4, 4, 2048)  0           ['sequential_19[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " up_sampling2d_12 (UpSampling2D  (None, 8, 8, 1024)  0           ['sequential_18[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " concatenate_13 (Concatenate)   (None, 4, 4, 3072)   0           ['sequential_18[0][0]',          \n",
      "                                                                  'up_sampling2d_13[0][0]']       \n",
      "                                                                                                  \n",
      " up_sampling2d_11 (UpSampling2D  (None, 16, 16, 512)  0          ['sequential_17[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " concatenate_12 (Concatenate)   (None, 8, 8, 1536)   0           ['sequential_17[0][0]',          \n",
      "                                                                  'up_sampling2d_12[0][0]']       \n",
      "                                                                                                  \n",
      " sequential_23 (Sequential)     (None, 4, 4, 1024)   4204544     ['concatenate_13[0][0]']         \n",
      "                                                                                                  \n",
      " up_sampling2d_10 (UpSampling2D  (None, 32, 32, 256)  0          ['sequential_16[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " concatenate_11 (Concatenate)   (None, 16, 16, 768)  0           ['sequential_16[0][0]',          \n",
      "                                                                  'up_sampling2d_11[0][0]']       \n",
      "                                                                                                  \n",
      " sequential_22 (Sequential)     (None, 8, 8, 512)    1053696     ['concatenate_12[0][0]']         \n",
      "                                                                                                  \n",
      " up_sampling2d_16 (UpSampling2D  (None, 8, 8, 1024)  0           ['sequential_23[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " concatenate_10 (Concatenate)   (None, 32, 32, 384)  0           ['sequential_15[0][0]',          \n",
      "                                                                  'up_sampling2d_10[0][0]']       \n",
      "                                                                                                  \n",
      " sequential_21 (Sequential)     (None, 16, 16, 256)  264704      ['concatenate_11[0][0]']         \n",
      "                                                                                                  \n",
      " up_sampling2d_15 (UpSampling2D  (None, 16, 16, 512)  0          ['sequential_22[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " concatenate_16 (Concatenate)   (None, 8, 8, 2048)   0           ['sequential_17[0][0]',          \n",
      "                                                                  'sequential_22[0][0]',          \n",
      "                                                                  'up_sampling2d_16[0][0]']       \n",
      "                                                                                                  \n",
      " sequential_20 (Sequential)     (None, 32, 32, 128)  66816       ['concatenate_10[0][0]']         \n",
      "                                                                                                  \n",
      " up_sampling2d_14 (UpSampling2D  (None, 32, 32, 256)  0          ['sequential_21[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " concatenate_15 (Concatenate)   (None, 16, 16, 1024  0           ['sequential_16[0][0]',          \n",
      "                                )                                 'sequential_21[0][0]',          \n",
      "                                                                  'up_sampling2d_15[0][0]']       \n",
      "                                                                                                  \n",
      " sequential_26 (Sequential)     (None, 8, 8, 512)    1315840     ['concatenate_16[0][0]']         \n",
      "                                                                                                  \n",
      " concatenate_14 (Concatenate)   (None, 32, 32, 512)  0           ['sequential_15[0][0]',          \n",
      "                                                                  'sequential_20[0][0]',          \n",
      "                                                                  'up_sampling2d_14[0][0]']       \n",
      "                                                                                                  \n",
      " sequential_25 (Sequential)     (None, 16, 16, 256)  330240      ['concatenate_15[0][0]']         \n",
      "                                                                                                  \n",
      " up_sampling2d_18 (UpSampling2D  (None, 16, 16, 512)  0          ['sequential_26[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " sequential_24 (Sequential)     (None, 32, 32, 128)  83200       ['concatenate_14[0][0]']         \n",
      "                                                                                                  \n",
      " up_sampling2d_17 (UpSampling2D  (None, 32, 32, 256)  0          ['sequential_25[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " concatenate_18 (Concatenate)   (None, 16, 16, 1280  0           ['sequential_16[0][0]',          \n",
      "                                )                                 'sequential_21[0][0]',          \n",
      "                                                                  'sequential_25[0][0]',          \n",
      "                                                                  'up_sampling2d_18[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_17 (Concatenate)   (None, 32, 32, 640)  0           ['sequential_15[0][0]',          \n",
      "                                                                  'sequential_20[0][0]',          \n",
      "                                                                  'sequential_24[0][0]',          \n",
      "                                                                  'up_sampling2d_17[0][0]']       \n",
      "                                                                                                  \n",
      " sequential_28 (Sequential)     (None, 16, 16, 256)  395776      ['concatenate_18[0][0]']         \n",
      "                                                                                                  \n",
      " sequential_27 (Sequential)     (None, 32, 32, 128)  99584       ['concatenate_17[0][0]']         \n",
      "                                                                                                  \n",
      " up_sampling2d_19 (UpSampling2D  (None, 32, 32, 256)  0          ['sequential_28[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " concatenate_19 (Concatenate)   (None, 32, 32, 768)  0           ['sequential_15[0][0]',          \n",
      "                                                                  'sequential_20[0][0]',          \n",
      "                                                                  'sequential_24[0][0]',          \n",
      "                                                                  'sequential_27[0][0]',          \n",
      "                                                                  'up_sampling2d_19[0][0]']       \n",
      "                                                                                                  \n",
      " sequential_29 (Sequential)     (None, 32, 32, 128)  115968      ['concatenate_19[0][0]']         \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 131072)       0           ['sequential_29[0][0]']          \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 1024)         134218752   ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 1)            1025        ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 150,562,433\n",
      "Trainable params: 150,533,249\n",
      "Non-trainable params: 29,184\n",
      "__________________________________________________________________________________________________\n",
      "{'filters': 128, 'units': 1024, '2nd dense': False, 'learning_rate': 0.001}\n"
     ]
    }
   ],
   "source": [
    "tunerA = kt.BayesianOptimization(unet_plus_plus_model,\n",
    "                     objective='val_loss',\n",
    "                     directory='my_dir',\n",
    "                     max_trials= 10,\n",
    "                     project_name='design_a',\n",
    "                    #  seed=42,\n",
    "                     )\n",
    "\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "tunerA.search(train_generator, epochs=100, validation_data=val_generator, callbacks=[stop_early])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hpsA=tunerA.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# Build the model with the best hp.\n",
    "modelA = unet_plus_plus_model(best_hpsA)\n",
    "modelA.summary()\n",
    "\n",
    "print(best_hpsA.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelA.save('design_models/designA.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelA = tf.keras.models.load_model('design_models/designA.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import rmtree\n",
    "# removing directory \n",
    "rmtree('my_dir') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segnet(hp):\n",
    "    hp_filters = hp.Choice('filters',values = [16,32,64])\n",
    "    # Encoding layer\n",
    "    img_input = Input(shape= (32,32,3))\n",
    "    x = Conv2D(hp_filters, (3, 3), padding='same', name='conv1',strides= (1,1))(img_input)\n",
    "    x = BatchNormalization(name='bn1')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(hp_filters, (3, 3), padding='same', name='conv2')(x)\n",
    "    x = BatchNormalization(name='bn2')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D()(x)\n",
    "    \n",
    "    x = Conv2D(hp_filters*2 , (3, 3), padding='same', name='conv3')(x)\n",
    "    x = BatchNormalization(name='bn3')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(hp_filters*2 , (3, 3), padding='same', name='conv4')(x)\n",
    "    x = BatchNormalization(name='bn4')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D()(x)\n",
    "\n",
    "    x = Conv2D(hp_filters*4, (3, 3), padding='same', name='conv5')(x)\n",
    "    x = BatchNormalization(name='bn5')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(hp_filters*4, (3, 3), padding='same', name='conv6')(x)\n",
    "    x = BatchNormalization(name='bn6')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(hp_filters*4, (3, 3), padding='same', name='conv7')(x)\n",
    "    x = BatchNormalization(name='bn7')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D()(x)\n",
    "\n",
    "    x = Conv2D(hp_filters*8, (3, 3), padding='same', name='conv8')(x)\n",
    "    x = BatchNormalization(name='bn8')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(hp_filters*8, (3, 3), padding='same', name='conv9')(x)\n",
    "    x = BatchNormalization(name='bn9')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(hp_filters*8, (3, 3), padding='same', name='conv10')(x)\n",
    "    x = BatchNormalization(name='bn10')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D()(x)\n",
    "    \n",
    "    x = Conv2D(hp_filters*8, (3, 3), padding='same', name='conv11')(x)\n",
    "    x = BatchNormalization(name='bn11')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(hp_filters*8, (3, 3), padding='same', name='conv12')(x)\n",
    "    x = BatchNormalization(name='bn12')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(hp_filters*8, (3, 3), padding='same', name='conv13')(x)\n",
    "    x = BatchNormalization(name='bn13')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D()(x)\n",
    "\n",
    "    x = Dense(hp_filters*16, activation = 'relu', name='fc1')(x)\n",
    "    x = Dense(hp_filters*16, activation = 'relu', name='fc2')(x)\n",
    "    # Decoding Layer \n",
    "    x = UpSampling2D()(x)\n",
    "    x = Conv2DTranspose(hp_filters*8, (3, 3), padding='same', name='deconv1')(x)\n",
    "    x = BatchNormalization(name='bn14')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2DTranspose(hp_filters*8, (3, 3), padding='same', name='deconv2')(x)\n",
    "    x = BatchNormalization(name='bn15')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2DTranspose(hp_filters*8, (3, 3), padding='same', name='deconv3')(x)\n",
    "    x = BatchNormalization(name='bn16')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = UpSampling2D()(x)\n",
    "    x = Conv2DTranspose(hp_filters*8, (3, 3), padding='same', name='deconv4')(x)\n",
    "    x = BatchNormalization(name='bn17')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2DTranspose(hp_filters*8, (3, 3), padding='same', name='deconv5')(x)\n",
    "    x = BatchNormalization(name='bn18')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2DTranspose(hp_filters*4, (3, 3), padding='same', name='deconv6')(x)\n",
    "    x = BatchNormalization(name='bn19')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = UpSampling2D()(x)\n",
    "    x = Conv2DTranspose(hp_filters*4, (3, 3), padding='same', name='deconv7')(x)\n",
    "    x = BatchNormalization(name='bn20')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2DTranspose(hp_filters*4, (3, 3), padding='same', name='deconv8')(x)\n",
    "    x = BatchNormalization(name='bn21')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2DTranspose(hp_filters*2, (3, 3), padding='same', name='deconv9')(x)\n",
    "    x = BatchNormalization(name='bn22')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = UpSampling2D()(x)\n",
    "    x = Conv2DTranspose(hp_filters*2, (3, 3), padding='same', name='deconv10')(x)\n",
    "    x = BatchNormalization(name='bn23')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2DTranspose(hp_filters, (3, 3), padding='same', name='deconv11')(x)\n",
    "    x = BatchNormalization(name='bn24')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = UpSampling2D()(x)\n",
    "    x = Conv2DTranspose(hp_filters, (3, 3), padding='same', name='deconv12')(x)\n",
    "    x = BatchNormalization(name='bn25')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    # x = Conv2DTranspose(1, (3, 3), padding='same', name='deconv13')(x)\n",
    "    # x = BatchNormalization(name='bn26')(x)\n",
    "    # x = Activation('sigmoid')(x)\n",
    "    # pred = Reshape((192,256))(x)\n",
    "    x = Flatten()(x)\n",
    "    hp_units = hp.Choice('units',values = [512,1024])\n",
    "    x = Dense(hp_units, activation='relu')(x)\n",
    "    if hp.Boolean(\"2nd dense\"):\n",
    "        x = Dense(hp_units, activation='relu')(x)\n",
    "    output=Dense(1, activation='linear')(x)\n",
    "    \n",
    "    model = Model(inputs=img_input, outputs=output)\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-3, 1e-4, 1e-5])\n",
    "    model.compile(optimizer= tf.keras.optimizers.Adam(lr=hp_learning_rate), loss= [\"mse\"]\n",
    "                  , metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 01m 38s]\n",
      "val_loss: 1.3124377727508545\n",
      "\n",
      "Best val_loss So Far: 1.1764636039733887\n",
      "Total elapsed time: 00h 14m 39s\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " conv1 (Conv2D)              (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " bn1 (BatchNormalization)    (None, 32, 32, 32)        128       \n",
      "                                                                 \n",
      " activation_25 (Activation)  (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2 (Conv2D)              (None, 32, 32, 32)        9248      \n",
      "                                                                 \n",
      " bn2 (BatchNormalization)    (None, 32, 32, 32)        128       \n",
      "                                                                 \n",
      " activation_26 (Activation)  (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 16, 16, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv3 (Conv2D)              (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " bn3 (BatchNormalization)    (None, 16, 16, 64)        256       \n",
      "                                                                 \n",
      " activation_27 (Activation)  (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " conv4 (Conv2D)              (None, 16, 16, 64)        36928     \n",
      "                                                                 \n",
      " bn4 (BatchNormalization)    (None, 16, 16, 64)        256       \n",
      "                                                                 \n",
      " activation_28 (Activation)  (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 8, 8, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv5 (Conv2D)              (None, 8, 8, 128)         73856     \n",
      "                                                                 \n",
      " bn5 (BatchNormalization)    (None, 8, 8, 128)         512       \n",
      "                                                                 \n",
      " activation_29 (Activation)  (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " conv6 (Conv2D)              (None, 8, 8, 128)         147584    \n",
      "                                                                 \n",
      " bn6 (BatchNormalization)    (None, 8, 8, 128)         512       \n",
      "                                                                 \n",
      " activation_30 (Activation)  (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " conv7 (Conv2D)              (None, 8, 8, 128)         147584    \n",
      "                                                                 \n",
      " bn7 (BatchNormalization)    (None, 8, 8, 128)         512       \n",
      "                                                                 \n",
      " activation_31 (Activation)  (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 4, 4, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv8 (Conv2D)              (None, 4, 4, 256)         295168    \n",
      "                                                                 \n",
      " bn8 (BatchNormalization)    (None, 4, 4, 256)         1024      \n",
      "                                                                 \n",
      " activation_32 (Activation)  (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " conv9 (Conv2D)              (None, 4, 4, 256)         590080    \n",
      "                                                                 \n",
      " bn9 (BatchNormalization)    (None, 4, 4, 256)         1024      \n",
      "                                                                 \n",
      " activation_33 (Activation)  (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " conv10 (Conv2D)             (None, 4, 4, 256)         590080    \n",
      "                                                                 \n",
      " bn10 (BatchNormalization)   (None, 4, 4, 256)         1024      \n",
      "                                                                 \n",
      " activation_34 (Activation)  (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 2, 2, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv11 (Conv2D)             (None, 2, 2, 256)         590080    \n",
      "                                                                 \n",
      " bn11 (BatchNormalization)   (None, 2, 2, 256)         1024      \n",
      "                                                                 \n",
      " activation_35 (Activation)  (None, 2, 2, 256)         0         \n",
      "                                                                 \n",
      " conv12 (Conv2D)             (None, 2, 2, 256)         590080    \n",
      "                                                                 \n",
      " bn12 (BatchNormalization)   (None, 2, 2, 256)         1024      \n",
      "                                                                 \n",
      " activation_36 (Activation)  (None, 2, 2, 256)         0         \n",
      "                                                                 \n",
      " conv13 (Conv2D)             (None, 2, 2, 256)         590080    \n",
      "                                                                 \n",
      " bn13 (BatchNormalization)   (None, 2, 2, 256)         1024      \n",
      "                                                                 \n",
      " activation_37 (Activation)  (None, 2, 2, 256)         0         \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 1, 1, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 1, 1, 512)         131584    \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 1, 1, 512)         262656    \n",
      "                                                                 \n",
      " up_sampling2d_5 (UpSampling  (None, 2, 2, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " deconv1 (Conv2DTranspose)   (None, 2, 2, 256)         1179904   \n",
      "                                                                 \n",
      " bn14 (BatchNormalization)   (None, 2, 2, 256)         1024      \n",
      "                                                                 \n",
      " activation_38 (Activation)  (None, 2, 2, 256)         0         \n",
      "                                                                 \n",
      " deconv2 (Conv2DTranspose)   (None, 2, 2, 256)         590080    \n",
      "                                                                 \n",
      " bn15 (BatchNormalization)   (None, 2, 2, 256)         1024      \n",
      "                                                                 \n",
      " activation_39 (Activation)  (None, 2, 2, 256)         0         \n",
      "                                                                 \n",
      " deconv3 (Conv2DTranspose)   (None, 2, 2, 256)         590080    \n",
      "                                                                 \n",
      " bn16 (BatchNormalization)   (None, 2, 2, 256)         1024      \n",
      "                                                                 \n",
      " activation_40 (Activation)  (None, 2, 2, 256)         0         \n",
      "                                                                 \n",
      " up_sampling2d_6 (UpSampling  (None, 4, 4, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " deconv4 (Conv2DTranspose)   (None, 4, 4, 256)         590080    \n",
      "                                                                 \n",
      " bn17 (BatchNormalization)   (None, 4, 4, 256)         1024      \n",
      "                                                                 \n",
      " activation_41 (Activation)  (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " deconv5 (Conv2DTranspose)   (None, 4, 4, 256)         590080    \n",
      "                                                                 \n",
      " bn18 (BatchNormalization)   (None, 4, 4, 256)         1024      \n",
      "                                                                 \n",
      " activation_42 (Activation)  (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " deconv6 (Conv2DTranspose)   (None, 4, 4, 128)         295040    \n",
      "                                                                 \n",
      " bn19 (BatchNormalization)   (None, 4, 4, 128)         512       \n",
      "                                                                 \n",
      " activation_43 (Activation)  (None, 4, 4, 128)         0         \n",
      "                                                                 \n",
      " up_sampling2d_7 (UpSampling  (None, 8, 8, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " deconv7 (Conv2DTranspose)   (None, 8, 8, 128)         147584    \n",
      "                                                                 \n",
      " bn20 (BatchNormalization)   (None, 8, 8, 128)         512       \n",
      "                                                                 \n",
      " activation_44 (Activation)  (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " deconv8 (Conv2DTranspose)   (None, 8, 8, 128)         147584    \n",
      "                                                                 \n",
      " bn21 (BatchNormalization)   (None, 8, 8, 128)         512       \n",
      "                                                                 \n",
      " activation_45 (Activation)  (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " deconv9 (Conv2DTranspose)   (None, 8, 8, 64)          73792     \n",
      "                                                                 \n",
      " bn22 (BatchNormalization)   (None, 8, 8, 64)          256       \n",
      "                                                                 \n",
      " activation_46 (Activation)  (None, 8, 8, 64)          0         \n",
      "                                                                 \n",
      " up_sampling2d_8 (UpSampling  (None, 16, 16, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " deconv10 (Conv2DTranspose)  (None, 16, 16, 64)        36928     \n",
      "                                                                 \n",
      " bn23 (BatchNormalization)   (None, 16, 16, 64)        256       \n",
      "                                                                 \n",
      " activation_47 (Activation)  (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " deconv11 (Conv2DTranspose)  (None, 16, 16, 32)        18464     \n",
      "                                                                 \n",
      " bn24 (BatchNormalization)   (None, 16, 16, 32)        128       \n",
      "                                                                 \n",
      " activation_48 (Activation)  (None, 16, 16, 32)        0         \n",
      "                                                                 \n",
      " up_sampling2d_9 (UpSampling  (None, 32, 32, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " deconv12 (Conv2DTranspose)  (None, 32, 32, 32)        9248      \n",
      "                                                                 \n",
      " bn25 (BatchNormalization)   (None, 32, 32, 32)        128       \n",
      "                                                                 \n",
      " activation_49 (Activation)  (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 32768)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               16777728  \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,137,377\n",
      "Trainable params: 25,129,441\n",
      "Non-trainable params: 7,936\n",
      "_________________________________________________________________\n",
      "{'filters': 32, 'units': 512, '2nd dense': False, 'learning_rate': 1e-05}\n"
     ]
    }
   ],
   "source": [
    "tunerB = kt.BayesianOptimization(segnet,\n",
    "                     objective='val_loss',\n",
    "                     directory='my_dir',\n",
    "                     max_trials= 10,\n",
    "                     project_name='design_a',\n",
    "                    #  seed=42,\n",
    "                     )\n",
    "\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "tunerB.search(train_generator, epochs=100, validation_data=val_generator, callbacks=[stop_early])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hpsB=tunerB.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# Build the model with the best hp.\n",
    "modelB = segnet(best_hpsB)\n",
    "modelB.summary()\n",
    "\n",
    "print(best_hpsB.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelB.save('design_models/designB.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import rmtree\n",
    "# removing directory \n",
    "rmtree('my_dir') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution_block(\n",
    "    block_input,\n",
    "    num_filters=256,\n",
    "    kernel_size=3,\n",
    "    dilation_rate=1,\n",
    "    padding=\"same\",\n",
    "    use_bias=False,\n",
    "):\n",
    "    x = layers.Conv2D(\n",
    "        num_filters,\n",
    "        kernel_size=kernel_size,\n",
    "        dilation_rate=dilation_rate,\n",
    "        padding=\"same\",\n",
    "        use_bias=use_bias,\n",
    "        kernel_initializer=keras.initializers.HeNormal(),\n",
    "    )(block_input)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "def DilatedSpatialPyramidPooling(dspp_input, num_filters):\n",
    "    dims = dspp_input.shape\n",
    "    x = layers.AveragePooling2D(pool_size=(dims[-3], dims[-2]))(dspp_input)\n",
    "    x = convolution_block(x, kernel_size=1, use_bias=True)\n",
    "    out_pool = layers.UpSampling2D(\n",
    "        size=(dims[-3] // x.shape[1], dims[-2] // x.shape[2]), interpolation=\"bilinear\",\n",
    "    )(x)\n",
    "\n",
    "    out_1 = convolution_block(dspp_input, num_filters=num_filters, kernel_size=1, dilation_rate=1)\n",
    "    out_6 = convolution_block(dspp_input, num_filters=num_filters,  kernel_size=3, dilation_rate=6)\n",
    "    out_12 = convolution_block(dspp_input, num_filters=num_filters,  kernel_size=3, dilation_rate=12)\n",
    "    out_18 = convolution_block(dspp_input, num_filters=num_filters,  kernel_size=3, dilation_rate=18)\n",
    "\n",
    "    x = layers.Concatenate(axis=-1)([out_pool, out_1, out_6, out_12, out_18])\n",
    "    output = convolution_block(x, kernel_size=1)\n",
    "    return output\n",
    "\n",
    "def DeeplabV3Plus(hp):\n",
    "    model_input = keras.Input(shape=(32, 32, 3))\n",
    "    resnet50 = keras.applications.ResNet50(\n",
    "        weights='imagenet', include_top=False, input_tensor=model_input\n",
    "    )\n",
    "    for layer in resnet50.layers:\n",
    "        layer.trainable=True\n",
    "    \n",
    "    hp_filters = hp.Choice('filters',values = [32,64,128])\n",
    "    x = resnet50.get_layer(\"conv4_block6_2_relu\").output\n",
    "    x = DilatedSpatialPyramidPooling(x, hp_filters*4)\n",
    "    image_size=32\n",
    "    input_a = layers.UpSampling2D(\n",
    "        size=(image_size // 4 // x.shape[1], image_size // 4 // x.shape[2]),\n",
    "        interpolation=\"bilinear\",\n",
    "    )(x)\n",
    "    input_b = resnet50.get_layer(\"conv2_block3_2_relu\").output\n",
    "    input_b = convolution_block(input_b, num_filters=hp_filters*2, kernel_size=1)\n",
    "\n",
    "    x = layers.Concatenate(axis=-1)([input_a, input_b])\n",
    "    x = convolution_block(x, num_filters=hp_filters*2)\n",
    "    x = convolution_block(x, num_filters=hp_filters)\n",
    "    x = layers.UpSampling2D(\n",
    "        size=(image_size // x.shape[1], image_size // x.shape[2]),\n",
    "        interpolation=\"bilinear\",\n",
    "    )(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    hp_units = hp.Choice('units',values = [256,512,1024])\n",
    "    x = Dense(hp_units, activation='relu')(x)\n",
    "    if hp.Boolean(\"2nd dense\"):\n",
    "        x = Dense(hp_units, activation='relu')(x)\n",
    "    model_output = layers.Dense(1, activation='linear')(x)\n",
    "    model  = keras.Model(inputs=model_input, outputs=model_output)\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-6, 1e-7, 1e-8])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(hp_learning_rate), loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "\n",
    "# modelC = DeeplabV3Plus(image_size=image_size[0])\n",
    "# modelC.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 00m 18s]\n",
      "val_loss: 2.5039288997650146\n",
      "\n",
      "Best val_loss So Far: 1.2538613080978394\n",
      "Total elapsed time: 00h 03m 01s\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 38, 38, 3)    0           ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 16, 16, 64)   9472        ['conv1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, 16, 16, 64)   256         ['conv1_conv[0][0]']             \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)        (None, 16, 16, 64)   0           ['conv1_bn[0][0]']               \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 18, 18, 64)   0           ['conv1_relu[0][0]']             \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 8, 8, 64)     0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 8, 8, 64)     4160        ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 8, 8, 64)     36928       ['conv2_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 8, 8, 256)    16640       ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 8, 8, 256)    16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)         (None, 8, 8, 256)    0           ['conv2_block1_0_bn[0][0]',      \n",
      "                                                                  'conv2_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activation)  (None, 8, 8, 256)    0           ['conv2_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 8, 8, 64)     16448       ['conv2_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 8, 8, 64)     36928       ['conv2_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 8, 8, 256)    16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_add (Add)         (None, 8, 8, 256)    0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activation)  (None, 8, 8, 256)    0           ['conv2_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 8, 8, 64)     16448       ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 8, 8, 64)     36928       ['conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 8, 8, 256)    16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)         (None, 8, 8, 256)    0           ['conv2_block2_out[0][0]',       \n",
      "                                                                  'conv2_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activation)  (None, 8, 8, 256)    0           ['conv2_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 4, 4, 128)    32896       ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 4, 4, 512)    131584      ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)         (None, 4, 4, 512)    0           ['conv3_block1_0_bn[0][0]',      \n",
      "                                                                  'conv3_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 4, 4, 128)    65664       ['conv3_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)         (None, 4, 4, 512)    0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 4, 4, 128)    65664       ['conv3_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)         (None, 4, 4, 512)    0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 4, 4, 128)    65664       ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)         (None, 4, 4, 512)    0           ['conv3_block3_out[0][0]',       \n",
      "                                                                  'conv3_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 2, 2, 256)    131328      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 2, 2, 1024)   525312      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block1_0_bn[0][0]',      \n",
      "                                                                  'conv4_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block1_out[0][0]',       \n",
      "                                                                  'conv4_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block2_out[0][0]',       \n",
      "                                                                  'conv4_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block3_out[0][0]',       \n",
      "                                                                  'conv4_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block5_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block4_out[0][0]',       \n",
      "                                                                  'conv4_block5_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block5_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " average_pooling2d_1 (AveragePo  (None, 1, 1, 256)   0           ['conv4_block6_2_relu[0][0]']    \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 1, 1, 256)    65792       ['average_pooling2d_1[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 1, 1, 256)   1024        ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 2, 2, 256)    65536       ['conv4_block6_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 2, 2, 256)    589824      ['conv4_block6_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 2, 2, 256)    589824      ['conv4_block6_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 2, 2, 256)    589824      ['conv4_block6_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " tf.nn.relu_9 (TFOpLambda)      (None, 1, 1, 256)    0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " up_sampling2d_3 (UpSampling2D)  (None, 2, 2, 256)   0           ['tf.nn.relu_9[0][0]']           \n",
      "                                                                                                  \n",
      " tf.nn.relu_10 (TFOpLambda)     (None, 2, 2, 256)    0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " tf.nn.relu_11 (TFOpLambda)     (None, 2, 2, 256)    0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " tf.nn.relu_12 (TFOpLambda)     (None, 2, 2, 256)    0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " tf.nn.relu_13 (TFOpLambda)     (None, 2, 2, 256)    0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 2, 2, 1280)   0           ['up_sampling2d_3[0][0]',        \n",
      "                                                                  'tf.nn.relu_10[0][0]',          \n",
      "                                                                  'tf.nn.relu_11[0][0]',          \n",
      "                                                                  'tf.nn.relu_12[0][0]',          \n",
      "                                                                  'tf.nn.relu_13[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 2, 2, 256)    327680      ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 8, 8, 128)    8192        ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " tf.nn.relu_14 (TFOpLambda)     (None, 2, 2, 256)    0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 8, 8, 128)   512         ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " up_sampling2d_4 (UpSampling2D)  (None, 8, 8, 256)   0           ['tf.nn.relu_14[0][0]']          \n",
      "                                                                                                  \n",
      " tf.nn.relu_15 (TFOpLambda)     (None, 8, 8, 128)    0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 8, 8, 384)    0           ['up_sampling2d_4[0][0]',        \n",
      "                                                                  'tf.nn.relu_15[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 8, 8, 128)    442368      ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 8, 8, 128)   512         ['conv2d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.nn.relu_16 (TFOpLambda)     (None, 8, 8, 128)    0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 8, 8, 64)     73728       ['tf.nn.relu_16[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 8, 8, 64)    256         ['conv2d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.nn.relu_17 (TFOpLambda)     (None, 8, 8, 64)     0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " up_sampling2d_5 (UpSampling2D)  (None, 32, 32, 64)  0           ['tf.nn.relu_17[0][0]']          \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 65536)        0           ['up_sampling2d_5[0][0]']        \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 256)          16777472    ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 256)          65792       ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 1)            257         ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 27,925,633\n",
      "Trainable params: 27,893,377\n",
      "Non-trainable params: 32,256\n",
      "__________________________________________________________________________________________________\n",
      "{'filters': 64, 'units': 256, '2nd dense': True, 'learning_rate': 1e-08}\n"
     ]
    }
   ],
   "source": [
    "tunerC = kt.BayesianOptimization(DeeplabV3Plus,\n",
    "                     objective='val_loss',\n",
    "                     directory='my_dir',\n",
    "                     max_trials= 10,\n",
    "                     project_name='design_a',\n",
    "                    #  seed=42,\n",
    "                     )\n",
    "\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "tunerC.search(train_generator, epochs=100, validation_data=val_generator, callbacks=[stop_early])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hpsC=tunerC.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# Build the model with the best hp.\n",
    "modelC = DeeplabV3Plus(best_hpsC)\n",
    "modelC.summary()\n",
    "\n",
    "print(best_hpsC.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelC.save('design_models/designC.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import rmtree\n",
    "# removing directory \n",
    "rmtree('my_dir') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MANUFACTURABILITY: TRAINING TIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 128\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
    "                              patience=4, min_lr=1e-9)\n",
    "# es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=16, mode=\"min\", restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 - 6s - loss: 59279.8398 - mae: 82.8080 - val_loss: 68.8713 - val_mae: 8.2236 - lr: 0.0010 - 6s/epoch - 375ms/step\n",
      "Epoch 2/128\n",
      "16/16 - 2s - loss: 138.2365 - mae: 11.4859 - val_loss: 66.0227 - val_mae: 8.0486 - lr: 0.0010 - 2s/epoch - 94ms/step\n",
      "Epoch 3/128\n",
      "16/16 - 2s - loss: 60.1051 - mae: 7.6556 - val_loss: 59.0941 - val_mae: 7.6061 - lr: 0.0010 - 2s/epoch - 94ms/step\n",
      "Epoch 4/128\n",
      "16/16 - 2s - loss: 57.5644 - mae: 7.5041 - val_loss: 57.3498 - val_mae: 7.4905 - lr: 0.0010 - 2s/epoch - 95ms/step\n",
      "Epoch 5/128\n",
      "16/16 - 2s - loss: 57.6032 - mae: 7.5062 - val_loss: 57.3336 - val_mae: 7.4894 - lr: 0.0010 - 2s/epoch - 94ms/step\n",
      "Epoch 6/128\n",
      "16/16 - 2s - loss: 57.5048 - mae: 7.5003 - val_loss: 57.3157 - val_mae: 7.4882 - lr: 0.0010 - 2s/epoch - 94ms/step\n",
      "Epoch 7/128\n",
      "16/16 - 2s - loss: 57.5007 - mae: 7.5002 - val_loss: 57.2962 - val_mae: 7.4869 - lr: 0.0010 - 2s/epoch - 94ms/step\n",
      "Epoch 8/128\n",
      "16/16 - 2s - loss: 57.4658 - mae: 7.4977 - val_loss: 57.2752 - val_mae: 7.4855 - lr: 0.0010 - 2s/epoch - 94ms/step\n",
      "Epoch 9/128\n",
      "16/16 - 2s - loss: 57.4678 - mae: 7.4979 - val_loss: 57.2527 - val_mae: 7.4840 - lr: 0.0010 - 2s/epoch - 94ms/step\n",
      "Epoch 10/128\n",
      "16/16 - 2s - loss: 57.4210 - mae: 7.4947 - val_loss: 57.2289 - val_mae: 7.4824 - lr: 0.0010 - 2s/epoch - 94ms/step\n",
      "Epoch 11/128\n",
      "16/16 - 2s - loss: 57.4010 - mae: 7.4934 - val_loss: 57.2039 - val_mae: 7.4808 - lr: 0.0010 - 2s/epoch - 95ms/step\n",
      "Epoch 12/128\n",
      "16/16 - 2s - loss: 57.3708 - mae: 7.4914 - val_loss: 57.1775 - val_mae: 7.4790 - lr: 0.0010 - 2s/epoch - 94ms/step\n",
      "Epoch 13/128\n",
      "16/16 - 2s - loss: 57.3497 - mae: 7.4900 - val_loss: 57.1500 - val_mae: 7.4771 - lr: 0.0010 - 2s/epoch - 95ms/step\n",
      "Epoch 14/128\n",
      "16/16 - 1s - loss: 57.3157 - mae: 7.4877 - val_loss: 57.1212 - val_mae: 7.4752 - lr: 0.0010 - 1s/epoch - 93ms/step\n",
      "Epoch 15/128\n",
      "16/16 - 2s - loss: 57.3015 - mae: 7.4867 - val_loss: 57.0913 - val_mae: 7.4732 - lr: 0.0010 - 2s/epoch - 94ms/step\n",
      "Epoch 16/128\n",
      "16/16 - 2s - loss: 57.2559 - mae: 7.4837 - val_loss: 57.0604 - val_mae: 7.4712 - lr: 0.0010 - 2s/epoch - 94ms/step\n",
      "Epoch 17/128\n",
      "16/16 - 1s - loss: 57.2244 - mae: 7.4816 - val_loss: 57.0284 - val_mae: 7.4690 - lr: 0.0010 - 1s/epoch - 94ms/step\n",
      "Epoch 18/128\n",
      "16/16 - 2s - loss: 57.1919 - mae: 7.4794 - val_loss: 56.9953 - val_mae: 7.4668 - lr: 0.0010 - 2s/epoch - 94ms/step\n",
      "Epoch 19/128\n",
      "16/16 - 2s - loss: 57.1582 - mae: 7.4772 - val_loss: 56.9612 - val_mae: 7.4645 - lr: 0.0010 - 2s/epoch - 94ms/step\n",
      "Epoch 20/128\n",
      "16/16 - 2s - loss: 57.1236 - mae: 7.4749 - val_loss: 56.9259 - val_mae: 7.4622 - lr: 0.0010 - 2s/epoch - 94ms/step\n",
      "Epoch 21/128\n",
      "16/16 - 2s - loss: 57.0879 - mae: 7.4725 - val_loss: 56.8899 - val_mae: 7.4597 - lr: 0.0010 - 2s/epoch - 95ms/step\n",
      "Epoch 22/128\n",
      "16/16 - 2s - loss: 57.0513 - mae: 7.4700 - val_loss: 56.8527 - val_mae: 7.4572 - lr: 0.0010 - 2s/epoch - 95ms/step\n",
      "Epoch 23/128\n",
      "16/16 - 2s - loss: 57.0135 - mae: 7.4675 - val_loss: 56.8148 - val_mae: 7.4547 - lr: 0.0010 - 2s/epoch - 94ms/step\n",
      "Epoch 24/128\n",
      "16/16 - 2s - loss: 56.9752 - mae: 7.4649 - val_loss: 56.7756 - val_mae: 7.4521 - lr: 0.0010 - 2s/epoch - 94ms/step\n",
      "Epoch 25/128\n",
      "16/16 - 2s - loss: 56.9390 - mae: 7.4626 - val_loss: 56.7357 - val_mae: 7.4494 - lr: 0.0010 - 2s/epoch - 94ms/step\n",
      "Epoch 26/128\n",
      "16/16 - 2s - loss: 56.8951 - mae: 7.4596 - val_loss: 56.6949 - val_mae: 7.4467 - lr: 0.0010 - 2s/epoch - 95ms/step\n",
      "Epoch 27/128\n",
      "16/16 - 2s - loss: 56.8538 - mae: 7.4568 - val_loss: 56.6531 - val_mae: 7.4438 - lr: 0.0010 - 2s/epoch - 94ms/step\n",
      "Epoch 28/128\n",
      "16/16 - 2s - loss: 56.8115 - mae: 7.4540 - val_loss: 56.6105 - val_mae: 7.4410 - lr: 0.0010 - 2s/epoch - 94ms/step\n",
      "Epoch 29/128\n",
      "16/16 - 2s - loss: 56.7683 - mae: 7.4511 - val_loss: 56.5669 - val_mae: 7.4381 - lr: 0.0010 - 2s/epoch - 95ms/step\n",
      "Epoch 30/128\n",
      "16/16 - 2s - loss: 56.7244 - mae: 7.4481 - val_loss: 56.5223 - val_mae: 7.4351 - lr: 0.0010 - 2s/epoch - 94ms/step\n",
      "Epoch 31/128\n",
      "16/16 - 2s - loss: 56.6793 - mae: 7.4451 - val_loss: 56.4771 - val_mae: 7.4320 - lr: 0.0010 - 2s/epoch - 94ms/step\n",
      "Epoch 32/128\n",
      "16/16 - 1s - loss: 56.6335 - mae: 7.4420 - val_loss: 56.4310 - val_mae: 7.4289 - lr: 0.0010 - 1s/epoch - 94ms/step\n",
      "Epoch 33/128\n",
      "16/16 - 2s - loss: 56.5870 - mae: 7.4389 - val_loss: 56.3838 - val_mae: 7.4257 - lr: 0.0010 - 2s/epoch - 95ms/step\n",
      "Epoch 34/128\n",
      "16/16 - 2s - loss: 56.5394 - mae: 7.4357 - val_loss: 56.3359 - val_mae: 7.4225 - lr: 0.0010 - 2s/epoch - 95ms/step\n",
      "Epoch 35/128\n",
      "16/16 - 1s - loss: 56.4910 - mae: 7.4324 - val_loss: 56.2872 - val_mae: 7.4192 - lr: 0.0010 - 1s/epoch - 94ms/step\n",
      "Epoch 36/128\n",
      "16/16 - 2s - loss: 56.4418 - mae: 7.4291 - val_loss: 56.2377 - val_mae: 7.4159 - lr: 0.0010 - 2s/epoch - 94ms/step\n",
      "Epoch 37/128\n",
      "16/16 - 2s - loss: 56.3919 - mae: 7.4258 - val_loss: 56.1872 - val_mae: 7.4125 - lr: 0.0010 - 2s/epoch - 97ms/step\n",
      "Epoch 38/128\n",
      "16/16 - 2s - loss: 56.3409 - mae: 7.4223 - val_loss: 56.1361 - val_mae: 7.4090 - lr: 0.0010 - 2s/epoch - 95ms/step\n",
      "Epoch 39/128\n",
      "16/16 - 2s - loss: 56.2893 - mae: 7.4188 - val_loss: 56.0840 - val_mae: 7.4055 - lr: 0.0010 - 2s/epoch - 95ms/step\n",
      "Epoch 40/128\n",
      "16/16 - 2s - loss: 56.2368 - mae: 7.4153 - val_loss: 56.0312 - val_mae: 7.4020 - lr: 0.0010 - 2s/epoch - 96ms/step\n",
      "Epoch 41/128\n",
      "16/16 - 2s - loss: 56.1834 - mae: 7.4117 - val_loss: 55.9776 - val_mae: 7.3983 - lr: 0.0010 - 2s/epoch - 98ms/step\n",
      "Epoch 42/128\n",
      "16/16 - 2s - loss: 56.1294 - mae: 7.4081 - val_loss: 55.9232 - val_mae: 7.3947 - lr: 0.0010 - 2s/epoch - 97ms/step\n",
      "Epoch 43/128\n",
      "16/16 - 2s - loss: 56.0746 - mae: 7.4044 - val_loss: 55.8678 - val_mae: 7.3909 - lr: 0.0010 - 2s/epoch - 95ms/step\n",
      "Epoch 44/128\n",
      "16/16 - 2s - loss: 56.0187 - mae: 7.4006 - val_loss: 55.8119 - val_mae: 7.3871 - lr: 0.0010 - 2s/epoch - 95ms/step\n",
      "Epoch 45/128\n",
      "16/16 - 2s - loss: 55.9623 - mae: 7.3968 - val_loss: 55.7552 - val_mae: 7.3833 - lr: 0.0010 - 2s/epoch - 94ms/step\n",
      "Epoch 46/128\n",
      "16/16 - 2s - loss: 55.9052 - mae: 7.3929 - val_loss: 55.6974 - val_mae: 7.3794 - lr: 0.0010 - 2s/epoch - 95ms/step\n",
      "Epoch 47/128\n",
      "16/16 - 2s - loss: 55.8470 - mae: 7.3890 - val_loss: 55.6390 - val_mae: 7.3754 - lr: 0.0010 - 2s/epoch - 97ms/step\n",
      "Epoch 48/128\n",
      "16/16 - 2s - loss: 55.7881 - mae: 7.3850 - val_loss: 55.5800 - val_mae: 7.3714 - lr: 0.0010 - 2s/epoch - 95ms/step\n",
      "Epoch 49/128\n",
      "16/16 - 2s - loss: 55.7286 - mae: 7.3810 - val_loss: 55.5201 - val_mae: 7.3674 - lr: 0.0010 - 2s/epoch - 96ms/step\n",
      "Epoch 50/128\n",
      "16/16 - 2s - loss: 55.6683 - mae: 7.3769 - val_loss: 55.4595 - val_mae: 7.3632 - lr: 0.0010 - 2s/epoch - 94ms/step\n",
      "Epoch 51/128\n",
      "16/16 - 2s - loss: 55.6072 - mae: 7.3727 - val_loss: 55.3980 - val_mae: 7.3591 - lr: 0.0010 - 2s/epoch - 95ms/step\n",
      "Epoch 52/128\n",
      "16/16 - 2s - loss: 55.5453 - mae: 7.3685 - val_loss: 55.3358 - val_mae: 7.3548 - lr: 0.0010 - 2s/epoch - 95ms/step\n",
      "Epoch 53/128\n",
      "16/16 - 2s - loss: 55.4827 - mae: 7.3643 - val_loss: 55.2729 - val_mae: 7.3506 - lr: 0.0010 - 2s/epoch - 95ms/step\n",
      "Epoch 54/128\n",
      "16/16 - 2s - loss: 55.4192 - mae: 7.3600 - val_loss: 55.2094 - val_mae: 7.3462 - lr: 0.0010 - 2s/epoch - 95ms/step\n",
      "Epoch 55/128\n",
      "16/16 - 2s - loss: 55.3625 - mae: 7.3560 - val_loss: 55.1447 - val_mae: 7.3418 - lr: 0.0010 - 2s/epoch - 95ms/step\n",
      "Epoch 56/128\n",
      "16/16 - 2s - loss: 55.2903 - mae: 7.3512 - val_loss: 55.0797 - val_mae: 7.3374 - lr: 0.0010 - 2s/epoch - 95ms/step\n",
      "Epoch 57/128\n",
      "16/16 - 2s - loss: 55.2248 - mae: 7.3467 - val_loss: 55.0137 - val_mae: 7.3329 - lr: 0.0010 - 2s/epoch - 95ms/step\n",
      "Epoch 58/128\n",
      "16/16 - 2s - loss: 55.1584 - mae: 7.3422 - val_loss: 54.9471 - val_mae: 7.3284 - lr: 0.0010 - 2s/epoch - 95ms/step\n",
      "Epoch 59/128\n",
      "16/16 - 2s - loss: 55.0913 - mae: 7.3377 - val_loss: 54.8797 - val_mae: 7.3238 - lr: 0.0010 - 2s/epoch - 95ms/step\n",
      "Epoch 60/128\n",
      "16/16 - 2s - loss: 55.0234 - mae: 7.3330 - val_loss: 54.8118 - val_mae: 7.3191 - lr: 0.0010 - 2s/epoch - 95ms/step\n",
      "Epoch 61/128\n",
      "16/16 - 2s - loss: 54.9551 - mae: 7.3284 - val_loss: 54.7428 - val_mae: 7.3144 - lr: 0.0010 - 2s/epoch - 95ms/step\n",
      "Epoch 62/128\n",
      "16/16 - 2s - loss: 54.8857 - mae: 7.3236 - val_loss: 54.6734 - val_mae: 7.3097 - lr: 0.0010 - 2s/epoch - 94ms/step\n",
      "Epoch 63/128\n",
      "16/16 - 2s - loss: 54.8157 - mae: 7.3189 - val_loss: 54.6033 - val_mae: 7.3049 - lr: 0.0010 - 2s/epoch - 95ms/step\n",
      "Epoch 64/128\n",
      "16/16 - 2s - loss: 54.7452 - mae: 7.3140 - val_loss: 54.5322 - val_mae: 7.3000 - lr: 0.0010 - 2s/epoch - 95ms/step\n",
      "Epoch 65/128\n",
      "16/16 - 2s - loss: 54.6735 - mae: 7.3092 - val_loss: 54.4607 - val_mae: 7.2951 - lr: 0.0010 - 2s/epoch - 94ms/step\n",
      "Epoch 66/128\n",
      "16/16 - 2s - loss: 54.6016 - mae: 7.3042 - val_loss: 54.3881 - val_mae: 7.2901 - lr: 0.0010 - 2s/epoch - 94ms/step\n",
      "Epoch 67/128\n",
      "16/16 - 2s - loss: 54.5287 - mae: 7.2992 - val_loss: 54.3150 - val_mae: 7.2851 - lr: 0.0010 - 2s/epoch - 95ms/step\n",
      "Epoch 68/128\n",
      "16/16 - 2s - loss: 54.4551 - mae: 7.2942 - val_loss: 54.2413 - val_mae: 7.2800 - lr: 0.0010 - 2s/epoch - 94ms/step\n",
      "Epoch 69/128\n",
      "16/16 - 2s - loss: 54.3810 - mae: 7.2891 - val_loss: 54.1667 - val_mae: 7.2749 - lr: 0.0010 - 2s/epoch - 94ms/step\n",
      "Epoch 70/128\n",
      "16/16 - 2s - loss: 54.3059 - mae: 7.2840 - val_loss: 54.0916 - val_mae: 7.2698 - lr: 0.0010 - 2s/epoch - 95ms/step\n",
      "Epoch 71/128\n",
      "16/16 - 2s - loss: 54.2304 - mae: 7.2788 - val_loss: 54.0157 - val_mae: 7.2645 - lr: 0.0010 - 2s/epoch - 95ms/step\n",
      "Epoch 72/128\n",
      "16/16 - 2s - loss: 54.1540 - mae: 7.2735 - val_loss: 53.9391 - val_mae: 7.2593 - lr: 0.0010 - 2s/epoch - 94ms/step\n",
      "Epoch 73/128\n",
      "16/16 - 2s - loss: 54.0770 - mae: 7.2682 - val_loss: 53.8618 - val_mae: 7.2539 - lr: 0.0010 - 2s/epoch - 95ms/step\n",
      "Epoch 74/128\n",
      "16/16 - 2s - loss: 53.9993 - mae: 7.2629 - val_loss: 53.7839 - val_mae: 7.2486 - lr: 0.0010 - 2s/epoch - 95ms/step\n",
      "Epoch 75/128\n",
      "16/16 - 2s - loss: 53.9208 - mae: 7.2575 - val_loss: 53.7054 - val_mae: 7.2431 - lr: 0.0010 - 2s/epoch - 95ms/step\n",
      "Epoch 76/128\n",
      "16/16 - 2s - loss: 53.8419 - mae: 7.2520 - val_loss: 53.6259 - val_mae: 7.2377 - lr: 0.0010 - 2s/epoch - 94ms/step\n",
      "Epoch 77/128\n",
      "16/16 - 2s - loss: 53.7619 - mae: 7.2465 - val_loss: 53.5461 - val_mae: 7.2321 - lr: 0.0010 - 2s/epoch - 95ms/step\n",
      "Epoch 78/128\n",
      "16/16 - 2s - loss: 53.6817 - mae: 7.2410 - val_loss: 53.4652 - val_mae: 7.2265 - lr: 0.0010 - 2s/epoch - 95ms/step\n",
      "Epoch 79/128\n",
      "16/16 - 2s - loss: 53.6003 - mae: 7.2354 - val_loss: 53.3840 - val_mae: 7.2209 - lr: 0.0010 - 2s/epoch - 94ms/step\n",
      "Epoch 80/128\n",
      "16/16 - 2s - loss: 53.5210 - mae: 7.2299 - val_loss: 53.3018 - val_mae: 7.2152 - lr: 0.0010 - 2s/epoch - 95ms/step\n",
      "Epoch 81/128\n",
      "16/16 - 2s - loss: 53.4361 - mae: 7.2240 - val_loss: 53.2192 - val_mae: 7.2095 - lr: 0.0010 - 2s/epoch - 94ms/step\n",
      "Epoch 82/128\n",
      "16/16 - 2s - loss: 53.3531 - mae: 7.2182 - val_loss: 53.1358 - val_mae: 7.2037 - lr: 0.0010 - 2s/epoch - 95ms/step\n",
      "Epoch 83/128\n",
      "16/16 - 2s - loss: 53.2693 - mae: 7.2124 - val_loss: 53.0518 - val_mae: 7.1979 - lr: 0.0010 - 2s/epoch - 95ms/step\n",
      "Epoch 84/128\n",
      "16/16 - 2s - loss: 53.1849 - mae: 7.2066 - val_loss: 52.9671 - val_mae: 7.1920 - lr: 0.0010 - 2s/epoch - 94ms/step\n",
      "Epoch 85/128\n",
      "16/16 - 2s - loss: 53.0998 - mae: 7.2007 - val_loss: 52.8817 - val_mae: 7.1861 - lr: 0.0010 - 2s/epoch - 95ms/step\n",
      "Epoch 86/128\n",
      "16/16 - 2s - loss: 53.0137 - mae: 7.1947 - val_loss: 52.7961 - val_mae: 7.1801 - lr: 0.0010 - 2s/epoch - 94ms/step\n",
      "Epoch 87/128\n",
      "16/16 - 2s - loss: 52.9276 - mae: 7.1887 - val_loss: 52.7095 - val_mae: 7.1741 - lr: 0.0010 - 2s/epoch - 95ms/step\n",
      "Epoch 88/128\n",
      "16/16 - 2s - loss: 52.8406 - mae: 7.1827 - val_loss: 52.6220 - val_mae: 7.1680 - lr: 0.0010 - 2s/epoch - 95ms/step\n",
      "Epoch 89/128\n",
      "16/16 - 2s - loss: 52.7527 - mae: 7.1765 - val_loss: 52.5341 - val_mae: 7.1618 - lr: 0.0010 - 2s/epoch - 95ms/step\n",
      "Epoch 90/128\n",
      "16/16 - 2s - loss: 52.6645 - mae: 7.1704 - val_loss: 52.4454 - val_mae: 7.1556 - lr: 0.0010 - 2s/epoch - 94ms/step\n",
      "Epoch 91/128\n",
      "16/16 - 2s - loss: 52.5753 - mae: 7.1642 - val_loss: 52.3564 - val_mae: 7.1494 - lr: 0.0010 - 2s/epoch - 95ms/step\n",
      "Epoch 92/128\n",
      "16/16 - 2s - loss: 52.4860 - mae: 7.1579 - val_loss: 52.2663 - val_mae: 7.1431 - lr: 0.0010 - 2s/epoch - 94ms/step\n",
      "Epoch 93/128\n",
      "16/16 - 2s - loss: 52.3956 - mae: 7.1516 - val_loss: 52.1758 - val_mae: 7.1368 - lr: 0.0010 - 2s/epoch - 95ms/step\n",
      "Epoch 94/128\n",
      "16/16 - 2s - loss: 52.3046 - mae: 7.1452 - val_loss: 52.0848 - val_mae: 7.1304 - lr: 0.0010 - 2s/epoch - 95ms/step\n",
      "Epoch 95/128\n",
      "16/16 - 2s - loss: 52.2131 - mae: 7.1388 - val_loss: 51.9932 - val_mae: 7.1240 - lr: 0.0010 - 2s/epoch - 94ms/step\n",
      "Epoch 96/128\n",
      "16/16 - 2s - loss: 52.1209 - mae: 7.1324 - val_loss: 51.9009 - val_mae: 7.1175 - lr: 0.0010 - 2s/epoch - 95ms/step\n",
      "Epoch 97/128\n",
      "16/16 - 2s - loss: 52.0283 - mae: 7.1259 - val_loss: 51.8078 - val_mae: 7.1109 - lr: 0.0010 - 2s/epoch - 94ms/step\n",
      "Epoch 98/128\n",
      "16/16 - 2s - loss: 51.9348 - mae: 7.1193 - val_loss: 51.7143 - val_mae: 7.1044 - lr: 0.0010 - 2s/epoch - 95ms/step\n",
      "Epoch 99/128\n",
      "16/16 - 2s - loss: 51.8407 - mae: 7.1127 - val_loss: 51.6201 - val_mae: 7.0977 - lr: 0.0010 - 2s/epoch - 95ms/step\n",
      "Epoch 100/128\n",
      "16/16 - 2s - loss: 51.7462 - mae: 7.1061 - val_loss: 51.5252 - val_mae: 7.0910 - lr: 0.0010 - 2s/epoch - 95ms/step\n",
      "Epoch 101/128\n",
      "16/16 - 2s - loss: 51.6509 - mae: 7.0994 - val_loss: 51.4299 - val_mae: 7.0843 - lr: 0.0010 - 2s/epoch - 95ms/step\n",
      "Epoch 102/128\n",
      "16/16 - 2s - loss: 51.5551 - mae: 7.0926 - val_loss: 51.3339 - val_mae: 7.0775 - lr: 0.0010 - 2s/epoch - 95ms/step\n",
      "Epoch 103/128\n",
      "16/16 - 2s - loss: 51.4586 - mae: 7.0858 - val_loss: 51.2373 - val_mae: 7.0707 - lr: 0.0010 - 2s/epoch - 95ms/step\n",
      "Epoch 104/128\n",
      "16/16 - 2s - loss: 51.3618 - mae: 7.0789 - val_loss: 51.1399 - val_mae: 7.0638 - lr: 0.0010 - 2s/epoch - 95ms/step\n",
      "Epoch 105/128\n",
      "16/16 - 2s - loss: 51.2640 - mae: 7.0720 - val_loss: 51.0420 - val_mae: 7.0569 - lr: 0.0010 - 2s/epoch - 95ms/step\n",
      "Epoch 106/128\n",
      "16/16 - 2s - loss: 51.1655 - mae: 7.0651 - val_loss: 50.9440 - val_mae: 7.0500 - lr: 0.0010 - 2s/epoch - 95ms/step\n",
      "Epoch 107/128\n",
      "16/16 - 2s - loss: 51.0669 - mae: 7.0581 - val_loss: 50.8451 - val_mae: 7.0429 - lr: 0.0010 - 2s/epoch - 94ms/step\n",
      "Epoch 108/128\n",
      "16/16 - 2s - loss: 50.9675 - mae: 7.0511 - val_loss: 50.7457 - val_mae: 7.0359 - lr: 0.0010 - 2s/epoch - 94ms/step\n",
      "Epoch 109/128\n",
      "16/16 - 2s - loss: 50.8675 - mae: 7.0440 - val_loss: 50.6456 - val_mae: 7.0288 - lr: 0.0010 - 2s/epoch - 95ms/step\n",
      "Epoch 110/128\n",
      "16/16 - 2s - loss: 50.7672 - mae: 7.0368 - val_loss: 50.5445 - val_mae: 7.0216 - lr: 0.0010 - 2s/epoch - 94ms/step\n",
      "Epoch 111/128\n",
      "16/16 - 2s - loss: 50.6658 - mae: 7.0296 - val_loss: 50.4434 - val_mae: 7.0144 - lr: 0.0010 - 2s/epoch - 94ms/step\n",
      "Epoch 112/128\n",
      "16/16 - 2s - loss: 50.5641 - mae: 7.0224 - val_loss: 50.3414 - val_mae: 7.0071 - lr: 0.0010 - 2s/epoch - 94ms/step\n",
      "Epoch 113/128\n",
      "16/16 - 2s - loss: 50.4618 - mae: 7.0151 - val_loss: 50.2390 - val_mae: 6.9998 - lr: 0.0010 - 2s/epoch - 95ms/step\n",
      "Epoch 114/128\n",
      "16/16 - 2s - loss: 50.3589 - mae: 7.0078 - val_loss: 50.1362 - val_mae: 6.9924 - lr: 0.0010 - 2s/epoch - 94ms/step\n",
      "Epoch 115/128\n",
      "16/16 - 2s - loss: 50.2558 - mae: 7.0004 - val_loss: 50.0322 - val_mae: 6.9850 - lr: 0.0010 - 2s/epoch - 95ms/step\n",
      "Epoch 116/128\n",
      "16/16 - 2s - loss: 50.1515 - mae: 6.9930 - val_loss: 49.9284 - val_mae: 6.9775 - lr: 0.0010 - 2s/epoch - 95ms/step\n",
      "Epoch 117/128\n",
      "16/16 - 2s - loss: 50.0469 - mae: 6.9855 - val_loss: 49.8240 - val_mae: 6.9701 - lr: 0.0010 - 2s/epoch - 95ms/step\n",
      "Epoch 118/128\n",
      "16/16 - 2s - loss: 49.9420 - mae: 6.9780 - val_loss: 49.7189 - val_mae: 6.9625 - lr: 0.0010 - 2s/epoch - 95ms/step\n",
      "Epoch 119/128\n",
      "16/16 - 2s - loss: 49.8365 - mae: 6.9704 - val_loss: 49.6130 - val_mae: 6.9549 - lr: 0.0010 - 2s/epoch - 95ms/step\n",
      "Epoch 120/128\n",
      "16/16 - 2s - loss: 49.7302 - mae: 6.9628 - val_loss: 49.5068 - val_mae: 6.9473 - lr: 0.0010 - 2s/epoch - 95ms/step\n",
      "Epoch 121/128\n",
      "16/16 - 2s - loss: 49.6236 - mae: 6.9551 - val_loss: 49.3999 - val_mae: 6.9396 - lr: 0.0010 - 2s/epoch - 94ms/step\n",
      "Epoch 122/128\n",
      "16/16 - 2s - loss: 49.5162 - mae: 6.9474 - val_loss: 49.2927 - val_mae: 6.9318 - lr: 0.0010 - 2s/epoch - 95ms/step\n",
      "Epoch 123/128\n",
      "16/16 - 2s - loss: 49.4085 - mae: 6.9397 - val_loss: 49.1849 - val_mae: 6.9241 - lr: 0.0010 - 2s/epoch - 94ms/step\n",
      "Epoch 124/128\n",
      "16/16 - 2s - loss: 49.3003 - mae: 6.9318 - val_loss: 49.0765 - val_mae: 6.9162 - lr: 0.0010 - 2s/epoch - 95ms/step\n",
      "Epoch 125/128\n",
      "16/16 - 2s - loss: 49.1915 - mae: 6.9240 - val_loss: 48.9674 - val_mae: 6.9083 - lr: 0.0010 - 2s/epoch - 95ms/step\n",
      "Epoch 126/128\n",
      "16/16 - 2s - loss: 49.0820 - mae: 6.9161 - val_loss: 48.8580 - val_mae: 6.9004 - lr: 0.0010 - 2s/epoch - 94ms/step\n",
      "Epoch 127/128\n",
      "16/16 - 2s - loss: 48.9724 - mae: 6.9081 - val_loss: 48.7479 - val_mae: 6.8924 - lr: 0.0010 - 2s/epoch - 95ms/step\n",
      "Epoch 128/128\n",
      "16/16 - 2s - loss: 48.8619 - mae: 6.9001 - val_loss: 48.6373 - val_mae: 6.8844 - lr: 0.0010 - 2s/epoch - 94ms/step\n",
      "Training time: 200.05600142478943s\n"
     ]
    }
   ],
   "source": [
    "## DESIGN A\n",
    "import time \n",
    "start = time.time()\n",
    "historyA = modelA.fit(train_generator, epochs=epochs, validation_data=val_generator, verbose=2, callbacks = [reduce_lr])\n",
    "stop = time.time()\n",
    "print(f\"Training time: {stop - start}s\")\n",
    "\n",
    "# ## FUNCTIONALITY: INFERENCE TIME\n",
    "# modelC.evaluate(train_generator[1][0][0].reshape(1,32,32,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 - 4s - loss: 17.6599 - mae: 3.1646 - val_loss: 46.1038 - val_mae: 6.6979 - lr: 1.0000e-05 - 4s/epoch - 229ms/step\n",
      "Epoch 2/128\n",
      "16/16 - 1s - loss: 2.7076 - mae: 1.3273 - val_loss: 34.4354 - val_mae: 5.7614 - lr: 1.0000e-05 - 578ms/epoch - 36ms/step\n",
      "Epoch 3/128\n",
      "16/16 - 1s - loss: 1.9221 - mae: 1.1406 - val_loss: 27.6696 - val_mae: 5.1408 - lr: 1.0000e-05 - 570ms/epoch - 36ms/step\n",
      "Epoch 4/128\n",
      "16/16 - 1s - loss: 1.6653 - mae: 1.1032 - val_loss: 19.9643 - val_mae: 4.3269 - lr: 1.0000e-05 - 571ms/epoch - 36ms/step\n",
      "Epoch 5/128\n",
      "16/16 - 1s - loss: 1.5556 - mae: 1.0519 - val_loss: 14.1858 - val_mae: 3.5977 - lr: 1.0000e-05 - 561ms/epoch - 35ms/step\n",
      "Epoch 6/128\n",
      "16/16 - 1s - loss: 1.5656 - mae: 1.0639 - val_loss: 9.5885 - val_mae: 2.8890 - lr: 1.0000e-05 - 594ms/epoch - 37ms/step\n",
      "Epoch 7/128\n",
      "16/16 - 1s - loss: 1.5770 - mae: 1.0481 - val_loss: 7.0582 - val_mae: 2.4117 - lr: 1.0000e-05 - 556ms/epoch - 35ms/step\n",
      "Epoch 8/128\n",
      "16/16 - 1s - loss: 1.5359 - mae: 1.0542 - val_loss: 4.6650 - val_mae: 1.8501 - lr: 1.0000e-05 - 565ms/epoch - 35ms/step\n",
      "Epoch 9/128\n",
      "16/16 - 1s - loss: 1.5301 - mae: 1.0439 - val_loss: 2.8234 - val_mae: 1.3738 - lr: 1.0000e-05 - 587ms/epoch - 37ms/step\n",
      "Epoch 10/128\n",
      "16/16 - 1s - loss: 1.6273 - mae: 1.0766 - val_loss: 2.1364 - val_mae: 1.2187 - lr: 1.0000e-05 - 603ms/epoch - 38ms/step\n",
      "Epoch 11/128\n",
      "16/16 - 1s - loss: 1.5147 - mae: 1.0568 - val_loss: 1.5947 - val_mae: 1.0445 - lr: 1.0000e-05 - 576ms/epoch - 36ms/step\n",
      "Epoch 12/128\n",
      "16/16 - 1s - loss: 1.6116 - mae: 1.0824 - val_loss: 1.4461 - val_mae: 0.9931 - lr: 1.0000e-05 - 560ms/epoch - 35ms/step\n",
      "Epoch 13/128\n",
      "16/16 - 1s - loss: 1.4779 - mae: 1.0369 - val_loss: 1.4966 - val_mae: 1.0018 - lr: 1.0000e-05 - 582ms/epoch - 36ms/step\n",
      "Epoch 14/128\n",
      "16/16 - 1s - loss: 1.4046 - mae: 1.0051 - val_loss: 1.3453 - val_mae: 0.9927 - lr: 1.0000e-05 - 552ms/epoch - 34ms/step\n",
      "Epoch 15/128\n",
      "16/16 - 1s - loss: 1.4653 - mae: 1.0195 - val_loss: 1.2503 - val_mae: 0.9928 - lr: 1.0000e-05 - 575ms/epoch - 36ms/step\n",
      "Epoch 16/128\n",
      "16/16 - 1s - loss: 1.3684 - mae: 0.9743 - val_loss: 1.2353 - val_mae: 0.9811 - lr: 1.0000e-05 - 569ms/epoch - 36ms/step\n",
      "Epoch 17/128\n",
      "16/16 - 1s - loss: 1.4689 - mae: 1.0226 - val_loss: 1.3870 - val_mae: 1.0024 - lr: 1.0000e-05 - 596ms/epoch - 37ms/step\n",
      "Epoch 18/128\n",
      "16/16 - 1s - loss: 1.4559 - mae: 1.0291 - val_loss: 1.4943 - val_mae: 1.0223 - lr: 1.0000e-05 - 581ms/epoch - 36ms/step\n",
      "Epoch 19/128\n",
      "16/16 - 1s - loss: 1.4587 - mae: 1.0216 - val_loss: 1.2958 - val_mae: 1.0074 - lr: 1.0000e-05 - 582ms/epoch - 36ms/step\n",
      "Epoch 20/128\n",
      "16/16 - 1s - loss: 1.4802 - mae: 1.0284 - val_loss: 1.6538 - val_mae: 1.0737 - lr: 1.0000e-05 - 587ms/epoch - 37ms/step\n",
      "Epoch 21/128\n",
      "16/16 - 1s - loss: 1.3776 - mae: 0.9913 - val_loss: 1.5831 - val_mae: 1.0528 - lr: 1.0000e-06 - 571ms/epoch - 36ms/step\n",
      "Epoch 22/128\n",
      "16/16 - 1s - loss: 1.4779 - mae: 1.0353 - val_loss: 1.4443 - val_mae: 1.0205 - lr: 1.0000e-06 - 581ms/epoch - 36ms/step\n",
      "Epoch 23/128\n",
      "16/16 - 1s - loss: 1.3577 - mae: 0.9853 - val_loss: 1.5970 - val_mae: 1.0682 - lr: 1.0000e-06 - 589ms/epoch - 37ms/step\n",
      "Epoch 24/128\n",
      "16/16 - 1s - loss: 1.4421 - mae: 1.0207 - val_loss: 1.6255 - val_mae: 1.0573 - lr: 1.0000e-06 - 589ms/epoch - 37ms/step\n",
      "Epoch 25/128\n",
      "16/16 - 1s - loss: 1.4054 - mae: 1.0129 - val_loss: 1.6607 - val_mae: 1.0669 - lr: 1.0000e-07 - 569ms/epoch - 36ms/step\n",
      "Epoch 26/128\n",
      "16/16 - 1s - loss: 1.3406 - mae: 0.9821 - val_loss: 1.6383 - val_mae: 1.0710 - lr: 1.0000e-07 - 578ms/epoch - 36ms/step\n",
      "Epoch 27/128\n",
      "16/16 - 1s - loss: 1.3699 - mae: 1.0070 - val_loss: 1.5934 - val_mae: 1.0650 - lr: 1.0000e-07 - 564ms/epoch - 35ms/step\n",
      "Epoch 28/128\n",
      "16/16 - 1s - loss: 1.4701 - mae: 1.0362 - val_loss: 1.5475 - val_mae: 1.0425 - lr: 1.0000e-07 - 585ms/epoch - 37ms/step\n",
      "Epoch 29/128\n",
      "16/16 - 1s - loss: 1.4057 - mae: 1.0088 - val_loss: 1.6211 - val_mae: 1.0967 - lr: 1.0000e-08 - 553ms/epoch - 35ms/step\n",
      "Epoch 30/128\n",
      "16/16 - 1s - loss: 1.4390 - mae: 1.0092 - val_loss: 1.6146 - val_mae: 1.1145 - lr: 1.0000e-08 - 562ms/epoch - 35ms/step\n",
      "Epoch 31/128\n",
      "16/16 - 1s - loss: 1.4060 - mae: 1.0058 - val_loss: 1.6780 - val_mae: 1.1068 - lr: 1.0000e-08 - 568ms/epoch - 36ms/step\n",
      "Epoch 32/128\n",
      "16/16 - 1s - loss: 1.3765 - mae: 0.9877 - val_loss: 1.5891 - val_mae: 1.0836 - lr: 1.0000e-08 - 553ms/epoch - 35ms/step\n",
      "Epoch 33/128\n",
      "16/16 - 1s - loss: 1.3434 - mae: 0.9804 - val_loss: 1.7143 - val_mae: 1.1129 - lr: 1.0000e-09 - 571ms/epoch - 36ms/step\n",
      "Epoch 34/128\n",
      "16/16 - 1s - loss: 1.3828 - mae: 1.0032 - val_loss: 1.7863 - val_mae: 1.1476 - lr: 1.0000e-09 - 554ms/epoch - 35ms/step\n",
      "Epoch 35/128\n",
      "16/16 - 1s - loss: 1.4433 - mae: 1.0141 - val_loss: 1.6296 - val_mae: 1.0965 - lr: 1.0000e-09 - 583ms/epoch - 36ms/step\n",
      "Epoch 36/128\n",
      "16/16 - 1s - loss: 1.3834 - mae: 0.9998 - val_loss: 1.6001 - val_mae: 1.0575 - lr: 1.0000e-09 - 609ms/epoch - 38ms/step\n",
      "Epoch 37/128\n",
      "16/16 - 1s - loss: 1.3835 - mae: 0.9991 - val_loss: 1.5059 - val_mae: 1.0351 - lr: 1.0000e-09 - 601ms/epoch - 38ms/step\n",
      "Epoch 38/128\n",
      "16/16 - 1s - loss: 1.3989 - mae: 0.9943 - val_loss: 1.4327 - val_mae: 1.0011 - lr: 1.0000e-09 - 571ms/epoch - 36ms/step\n",
      "Epoch 39/128\n",
      "16/16 - 1s - loss: 1.4440 - mae: 1.0265 - val_loss: 1.4963 - val_mae: 1.0309 - lr: 1.0000e-09 - 573ms/epoch - 36ms/step\n",
      "Epoch 40/128\n",
      "16/16 - 1s - loss: 1.4727 - mae: 1.0338 - val_loss: 1.5811 - val_mae: 1.0582 - lr: 1.0000e-09 - 553ms/epoch - 35ms/step\n",
      "Epoch 41/128\n",
      "16/16 - 1s - loss: 1.3900 - mae: 1.0044 - val_loss: 1.4787 - val_mae: 1.0303 - lr: 1.0000e-09 - 612ms/epoch - 38ms/step\n",
      "Epoch 42/128\n",
      "16/16 - 1s - loss: 1.4194 - mae: 1.0035 - val_loss: 1.3046 - val_mae: 0.9756 - lr: 1.0000e-09 - 582ms/epoch - 36ms/step\n",
      "Epoch 43/128\n",
      "16/16 - 1s - loss: 1.4363 - mae: 1.0266 - val_loss: 1.3501 - val_mae: 1.0126 - lr: 1.0000e-09 - 593ms/epoch - 37ms/step\n",
      "Epoch 44/128\n",
      "16/16 - 1s - loss: 1.4613 - mae: 1.0373 - val_loss: 1.3296 - val_mae: 0.9848 - lr: 1.0000e-09 - 575ms/epoch - 36ms/step\n",
      "Epoch 45/128\n",
      "16/16 - 1s - loss: 1.3371 - mae: 0.9700 - val_loss: 1.4312 - val_mae: 1.0265 - lr: 1.0000e-09 - 564ms/epoch - 35ms/step\n",
      "Epoch 46/128\n",
      "16/16 - 1s - loss: 1.4962 - mae: 1.0284 - val_loss: 1.4381 - val_mae: 1.0374 - lr: 1.0000e-09 - 583ms/epoch - 36ms/step\n",
      "Epoch 47/128\n",
      "16/16 - 1s - loss: 1.3806 - mae: 1.0062 - val_loss: 1.4260 - val_mae: 1.0335 - lr: 1.0000e-09 - 564ms/epoch - 35ms/step\n",
      "Epoch 48/128\n",
      "16/16 - 1s - loss: 1.4448 - mae: 1.0258 - val_loss: 1.5271 - val_mae: 1.0765 - lr: 1.0000e-09 - 566ms/epoch - 35ms/step\n",
      "Epoch 49/128\n",
      "16/16 - 1s - loss: 1.4132 - mae: 1.0119 - val_loss: 1.5997 - val_mae: 1.0945 - lr: 1.0000e-09 - 566ms/epoch - 35ms/step\n",
      "Epoch 50/128\n",
      "16/16 - 1s - loss: 1.4564 - mae: 1.0247 - val_loss: 1.6079 - val_mae: 1.0963 - lr: 1.0000e-09 - 562ms/epoch - 35ms/step\n",
      "Epoch 51/128\n",
      "16/16 - 1s - loss: 1.4075 - mae: 0.9978 - val_loss: 1.5722 - val_mae: 1.0797 - lr: 1.0000e-09 - 567ms/epoch - 35ms/step\n",
      "Epoch 52/128\n",
      "16/16 - 1s - loss: 1.3826 - mae: 1.0059 - val_loss: 1.5474 - val_mae: 1.0793 - lr: 1.0000e-09 - 557ms/epoch - 35ms/step\n",
      "Epoch 53/128\n",
      "16/16 - 1s - loss: 1.3415 - mae: 0.9801 - val_loss: 1.4523 - val_mae: 1.0477 - lr: 1.0000e-09 - 586ms/epoch - 37ms/step\n",
      "Epoch 54/128\n",
      "16/16 - 1s - loss: 1.3665 - mae: 0.9985 - val_loss: 1.4349 - val_mae: 1.0338 - lr: 1.0000e-09 - 573ms/epoch - 36ms/step\n",
      "Epoch 55/128\n",
      "16/16 - 1s - loss: 1.4168 - mae: 1.0066 - val_loss: 1.4396 - val_mae: 1.0169 - lr: 1.0000e-09 - 593ms/epoch - 37ms/step\n",
      "Epoch 56/128\n",
      "16/16 - 1s - loss: 1.4627 - mae: 1.0259 - val_loss: 1.4599 - val_mae: 1.0294 - lr: 1.0000e-09 - 567ms/epoch - 35ms/step\n",
      "Epoch 57/128\n",
      "16/16 - 1s - loss: 1.4452 - mae: 1.0299 - val_loss: 1.4754 - val_mae: 1.0274 - lr: 1.0000e-09 - 583ms/epoch - 36ms/step\n",
      "Epoch 58/128\n",
      "16/16 - 1s - loss: 1.4576 - mae: 1.0343 - val_loss: 1.5006 - val_mae: 1.0278 - lr: 1.0000e-09 - 570ms/epoch - 36ms/step\n",
      "Epoch 59/128\n",
      "16/16 - 1s - loss: 1.3870 - mae: 1.0017 - val_loss: 1.4818 - val_mae: 1.0192 - lr: 1.0000e-09 - 585ms/epoch - 37ms/step\n",
      "Epoch 60/128\n",
      "16/16 - 1s - loss: 1.4614 - mae: 1.0173 - val_loss: 1.5004 - val_mae: 1.0251 - lr: 1.0000e-09 - 574ms/epoch - 36ms/step\n",
      "Epoch 61/128\n",
      "16/16 - 1s - loss: 1.4018 - mae: 1.0068 - val_loss: 1.4492 - val_mae: 1.0065 - lr: 1.0000e-09 - 574ms/epoch - 36ms/step\n",
      "Epoch 62/128\n",
      "16/16 - 1s - loss: 1.3945 - mae: 0.9972 - val_loss: 1.4924 - val_mae: 1.0244 - lr: 1.0000e-09 - 548ms/epoch - 34ms/step\n",
      "Epoch 63/128\n",
      "16/16 - 1s - loss: 1.4612 - mae: 1.0274 - val_loss: 1.4637 - val_mae: 1.0151 - lr: 1.0000e-09 - 577ms/epoch - 36ms/step\n",
      "Epoch 64/128\n",
      "16/16 - 1s - loss: 1.3927 - mae: 0.9865 - val_loss: 1.4499 - val_mae: 1.0072 - lr: 1.0000e-09 - 558ms/epoch - 35ms/step\n",
      "Epoch 65/128\n",
      "16/16 - 1s - loss: 1.4047 - mae: 1.0078 - val_loss: 1.4199 - val_mae: 0.9974 - lr: 1.0000e-09 - 561ms/epoch - 35ms/step\n",
      "Epoch 66/128\n",
      "16/16 - 1s - loss: 1.4135 - mae: 0.9985 - val_loss: 1.3757 - val_mae: 0.9800 - lr: 1.0000e-09 - 559ms/epoch - 35ms/step\n",
      "Epoch 67/128\n",
      "16/16 - 1s - loss: 1.4530 - mae: 1.0254 - val_loss: 1.3795 - val_mae: 0.9881 - lr: 1.0000e-09 - 549ms/epoch - 34ms/step\n",
      "Epoch 68/128\n",
      "16/16 - 1s - loss: 1.3411 - mae: 0.9741 - val_loss: 1.3785 - val_mae: 0.9846 - lr: 1.0000e-09 - 576ms/epoch - 36ms/step\n",
      "Epoch 69/128\n",
      "16/16 - 1s - loss: 1.3835 - mae: 1.0040 - val_loss: 1.3894 - val_mae: 0.9977 - lr: 1.0000e-09 - 563ms/epoch - 35ms/step\n",
      "Epoch 70/128\n",
      "16/16 - 1s - loss: 1.4498 - mae: 1.0377 - val_loss: 1.3741 - val_mae: 0.9739 - lr: 1.0000e-09 - 595ms/epoch - 37ms/step\n",
      "Epoch 71/128\n",
      "16/16 - 1s - loss: 1.4304 - mae: 1.0179 - val_loss: 1.4071 - val_mae: 0.9987 - lr: 1.0000e-09 - 566ms/epoch - 35ms/step\n",
      "Epoch 72/128\n",
      "16/16 - 1s - loss: 1.3820 - mae: 0.9915 - val_loss: 1.3865 - val_mae: 0.9842 - lr: 1.0000e-09 - 576ms/epoch - 36ms/step\n",
      "Epoch 73/128\n",
      "16/16 - 1s - loss: 1.5041 - mae: 1.0530 - val_loss: 1.3632 - val_mae: 0.9911 - lr: 1.0000e-09 - 560ms/epoch - 35ms/step\n",
      "Epoch 74/128\n",
      "16/16 - 1s - loss: 1.4044 - mae: 0.9934 - val_loss: 1.3569 - val_mae: 0.9751 - lr: 1.0000e-09 - 570ms/epoch - 36ms/step\n",
      "Epoch 75/128\n",
      "16/16 - 1s - loss: 1.3609 - mae: 0.9927 - val_loss: 1.3743 - val_mae: 0.9828 - lr: 1.0000e-09 - 566ms/epoch - 35ms/step\n",
      "Epoch 76/128\n",
      "16/16 - 1s - loss: 1.2970 - mae: 0.9726 - val_loss: 1.3735 - val_mae: 0.9891 - lr: 1.0000e-09 - 553ms/epoch - 35ms/step\n",
      "Epoch 77/128\n",
      "16/16 - 1s - loss: 1.4119 - mae: 1.0074 - val_loss: 1.4065 - val_mae: 1.0007 - lr: 1.0000e-09 - 584ms/epoch - 37ms/step\n",
      "Epoch 78/128\n",
      "16/16 - 1s - loss: 1.3988 - mae: 1.0092 - val_loss: 1.4535 - val_mae: 1.0177 - lr: 1.0000e-09 - 560ms/epoch - 35ms/step\n",
      "Epoch 79/128\n",
      "16/16 - 1s - loss: 1.4373 - mae: 1.0228 - val_loss: 1.4766 - val_mae: 1.0227 - lr: 1.0000e-09 - 576ms/epoch - 36ms/step\n",
      "Epoch 80/128\n",
      "16/16 - 1s - loss: 1.4356 - mae: 1.0180 - val_loss: 1.4976 - val_mae: 1.0217 - lr: 1.0000e-09 - 557ms/epoch - 35ms/step\n",
      "Epoch 81/128\n",
      "16/16 - 1s - loss: 1.2817 - mae: 0.9678 - val_loss: 1.4601 - val_mae: 1.0162 - lr: 1.0000e-09 - 595ms/epoch - 37ms/step\n",
      "Epoch 82/128\n",
      "16/16 - 1s - loss: 1.3728 - mae: 0.9903 - val_loss: 1.4110 - val_mae: 0.9959 - lr: 1.0000e-09 - 574ms/epoch - 36ms/step\n",
      "Epoch 83/128\n",
      "16/16 - 1s - loss: 1.3297 - mae: 0.9884 - val_loss: 1.4040 - val_mae: 0.9990 - lr: 1.0000e-09 - 561ms/epoch - 35ms/step\n",
      "Epoch 84/128\n",
      "16/16 - 1s - loss: 1.4720 - mae: 1.0259 - val_loss: 1.3805 - val_mae: 0.9850 - lr: 1.0000e-09 - 568ms/epoch - 35ms/step\n",
      "Epoch 85/128\n",
      "16/16 - 1s - loss: 1.3662 - mae: 0.9953 - val_loss: 1.3506 - val_mae: 0.9747 - lr: 1.0000e-09 - 575ms/epoch - 36ms/step\n",
      "Epoch 86/128\n",
      "16/16 - 1s - loss: 1.4330 - mae: 1.0192 - val_loss: 1.3985 - val_mae: 0.9994 - lr: 1.0000e-09 - 581ms/epoch - 36ms/step\n",
      "Epoch 87/128\n",
      "16/16 - 1s - loss: 1.4683 - mae: 1.0353 - val_loss: 1.4250 - val_mae: 1.0122 - lr: 1.0000e-09 - 571ms/epoch - 36ms/step\n",
      "Epoch 88/128\n",
      "16/16 - 1s - loss: 1.4248 - mae: 1.0117 - val_loss: 1.4408 - val_mae: 1.0169 - lr: 1.0000e-09 - 577ms/epoch - 36ms/step\n",
      "Epoch 89/128\n",
      "16/16 - 1s - loss: 1.3205 - mae: 0.9736 - val_loss: 1.3967 - val_mae: 1.0005 - lr: 1.0000e-09 - 593ms/epoch - 37ms/step\n",
      "Epoch 90/128\n",
      "16/16 - 1s - loss: 1.4193 - mae: 1.0085 - val_loss: 1.3897 - val_mae: 0.9975 - lr: 1.0000e-09 - 561ms/epoch - 35ms/step\n",
      "Epoch 91/128\n",
      "16/16 - 1s - loss: 1.4352 - mae: 1.0195 - val_loss: 1.3663 - val_mae: 0.9891 - lr: 1.0000e-09 - 554ms/epoch - 35ms/step\n",
      "Epoch 92/128\n",
      "16/16 - 1s - loss: 1.3823 - mae: 0.9867 - val_loss: 1.3698 - val_mae: 0.9891 - lr: 1.0000e-09 - 555ms/epoch - 35ms/step\n",
      "Epoch 93/128\n",
      "16/16 - 1s - loss: 1.4018 - mae: 1.0060 - val_loss: 1.3671 - val_mae: 0.9900 - lr: 1.0000e-09 - 572ms/epoch - 36ms/step\n",
      "Epoch 94/128\n",
      "16/16 - 1s - loss: 1.3691 - mae: 0.9868 - val_loss: 1.4107 - val_mae: 1.0063 - lr: 1.0000e-09 - 558ms/epoch - 35ms/step\n",
      "Epoch 95/128\n",
      "16/16 - 1s - loss: 1.4259 - mae: 1.0181 - val_loss: 1.4157 - val_mae: 1.0101 - lr: 1.0000e-09 - 575ms/epoch - 36ms/step\n",
      "Epoch 96/128\n",
      "16/16 - 1s - loss: 1.3993 - mae: 1.0024 - val_loss: 1.4416 - val_mae: 1.0247 - lr: 1.0000e-09 - 563ms/epoch - 35ms/step\n",
      "Epoch 97/128\n",
      "16/16 - 1s - loss: 1.4416 - mae: 1.0164 - val_loss: 1.4072 - val_mae: 1.0031 - lr: 1.0000e-09 - 582ms/epoch - 36ms/step\n",
      "Epoch 98/128\n",
      "16/16 - 1s - loss: 1.4106 - mae: 1.0140 - val_loss: 1.4221 - val_mae: 1.0068 - lr: 1.0000e-09 - 568ms/epoch - 35ms/step\n",
      "Epoch 99/128\n",
      "16/16 - 1s - loss: 1.3598 - mae: 0.9946 - val_loss: 1.4650 - val_mae: 1.0374 - lr: 1.0000e-09 - 575ms/epoch - 36ms/step\n",
      "Epoch 100/128\n",
      "16/16 - 1s - loss: 1.4501 - mae: 1.0173 - val_loss: 1.4628 - val_mae: 1.0376 - lr: 1.0000e-09 - 559ms/epoch - 35ms/step\n",
      "Epoch 101/128\n",
      "16/16 - 1s - loss: 1.4150 - mae: 1.0321 - val_loss: 1.4611 - val_mae: 1.0415 - lr: 1.0000e-09 - 572ms/epoch - 36ms/step\n",
      "Epoch 102/128\n",
      "16/16 - 1s - loss: 1.3280 - mae: 0.9781 - val_loss: 1.4622 - val_mae: 1.0418 - lr: 1.0000e-09 - 592ms/epoch - 37ms/step\n",
      "Epoch 103/128\n",
      "16/16 - 1s - loss: 1.3320 - mae: 0.9857 - val_loss: 1.4025 - val_mae: 0.9998 - lr: 1.0000e-09 - 572ms/epoch - 36ms/step\n",
      "Epoch 104/128\n",
      "16/16 - 1s - loss: 1.3873 - mae: 1.0075 - val_loss: 1.4205 - val_mae: 1.0136 - lr: 1.0000e-09 - 570ms/epoch - 36ms/step\n",
      "Epoch 105/128\n",
      "16/16 - 1s - loss: 1.4105 - mae: 1.0152 - val_loss: 1.4151 - val_mae: 0.9992 - lr: 1.0000e-09 - 560ms/epoch - 35ms/step\n",
      "Epoch 106/128\n",
      "16/16 - 1s - loss: 1.4493 - mae: 1.0192 - val_loss: 1.4908 - val_mae: 1.0331 - lr: 1.0000e-09 - 589ms/epoch - 37ms/step\n",
      "Epoch 107/128\n",
      "16/16 - 1s - loss: 1.5159 - mae: 1.0488 - val_loss: 1.4851 - val_mae: 1.0265 - lr: 1.0000e-09 - 556ms/epoch - 35ms/step\n",
      "Epoch 108/128\n",
      "16/16 - 1s - loss: 1.4174 - mae: 1.0121 - val_loss: 1.4725 - val_mae: 1.0245 - lr: 1.0000e-09 - 565ms/epoch - 35ms/step\n",
      "Epoch 109/128\n",
      "16/16 - 1s - loss: 1.4327 - mae: 1.0130 - val_loss: 1.4617 - val_mae: 1.0172 - lr: 1.0000e-09 - 589ms/epoch - 37ms/step\n",
      "Epoch 110/128\n",
      "16/16 - 1s - loss: 1.3301 - mae: 0.9823 - val_loss: 1.4538 - val_mae: 1.0211 - lr: 1.0000e-09 - 581ms/epoch - 36ms/step\n",
      "Epoch 111/128\n",
      "16/16 - 1s - loss: 1.3749 - mae: 0.9977 - val_loss: 1.4686 - val_mae: 1.0259 - lr: 1.0000e-09 - 564ms/epoch - 35ms/step\n",
      "Epoch 112/128\n",
      "16/16 - 1s - loss: 1.4372 - mae: 1.0110 - val_loss: 1.4282 - val_mae: 1.0113 - lr: 1.0000e-09 - 549ms/epoch - 34ms/step\n",
      "Epoch 113/128\n",
      "16/16 - 1s - loss: 1.4767 - mae: 1.0414 - val_loss: 1.5181 - val_mae: 1.0328 - lr: 1.0000e-09 - 579ms/epoch - 36ms/step\n",
      "Epoch 114/128\n",
      "16/16 - 1s - loss: 1.3780 - mae: 1.0003 - val_loss: 1.4932 - val_mae: 1.0395 - lr: 1.0000e-09 - 549ms/epoch - 34ms/step\n",
      "Epoch 115/128\n",
      "16/16 - 1s - loss: 1.5743 - mae: 1.0780 - val_loss: 1.4870 - val_mae: 1.0386 - lr: 1.0000e-09 - 570ms/epoch - 36ms/step\n",
      "Epoch 116/128\n",
      "16/16 - 1s - loss: 1.5268 - mae: 1.0466 - val_loss: 1.4983 - val_mae: 1.0294 - lr: 1.0000e-09 - 550ms/epoch - 34ms/step\n",
      "Epoch 117/128\n",
      "16/16 - 1s - loss: 1.3991 - mae: 1.0083 - val_loss: 1.4921 - val_mae: 1.0260 - lr: 1.0000e-09 - 587ms/epoch - 37ms/step\n",
      "Epoch 118/128\n",
      "16/16 - 1s - loss: 1.4164 - mae: 1.0174 - val_loss: 1.5366 - val_mae: 1.0374 - lr: 1.0000e-09 - 564ms/epoch - 35ms/step\n",
      "Epoch 119/128\n",
      "16/16 - 1s - loss: 1.3843 - mae: 0.9915 - val_loss: 1.5374 - val_mae: 1.0417 - lr: 1.0000e-09 - 555ms/epoch - 35ms/step\n",
      "Epoch 120/128\n",
      "16/16 - 1s - loss: 1.3714 - mae: 0.9839 - val_loss: 1.4862 - val_mae: 1.0320 - lr: 1.0000e-09 - 560ms/epoch - 35ms/step\n",
      "Epoch 121/128\n",
      "16/16 - 1s - loss: 1.4730 - mae: 1.0357 - val_loss: 1.4767 - val_mae: 1.0319 - lr: 1.0000e-09 - 569ms/epoch - 36ms/step\n",
      "Epoch 122/128\n",
      "16/16 - 1s - loss: 1.3776 - mae: 0.9938 - val_loss: 1.4726 - val_mae: 1.0257 - lr: 1.0000e-09 - 562ms/epoch - 35ms/step\n",
      "Epoch 123/128\n",
      "16/16 - 1s - loss: 1.4857 - mae: 1.0257 - val_loss: 1.4825 - val_mae: 1.0320 - lr: 1.0000e-09 - 551ms/epoch - 34ms/step\n",
      "Epoch 124/128\n",
      "16/16 - 1s - loss: 1.4438 - mae: 1.0070 - val_loss: 1.4255 - val_mae: 1.0016 - lr: 1.0000e-09 - 577ms/epoch - 36ms/step\n",
      "Epoch 125/128\n",
      "16/16 - 1s - loss: 1.4830 - mae: 1.0298 - val_loss: 1.4970 - val_mae: 1.0327 - lr: 1.0000e-09 - 585ms/epoch - 37ms/step\n",
      "Epoch 126/128\n",
      "16/16 - 1s - loss: 1.3840 - mae: 0.9984 - val_loss: 1.4275 - val_mae: 0.9970 - lr: 1.0000e-09 - 586ms/epoch - 37ms/step\n",
      "Epoch 127/128\n",
      "16/16 - 1s - loss: 1.3799 - mae: 0.9997 - val_loss: 1.5028 - val_mae: 1.0281 - lr: 1.0000e-09 - 557ms/epoch - 35ms/step\n",
      "Epoch 128/128\n",
      "16/16 - 1s - loss: 1.3401 - mae: 0.9829 - val_loss: 1.4489 - val_mae: 1.0018 - lr: 1.0000e-09 - 580ms/epoch - 36ms/step\n",
      "Training time: 77.96902847290039s\n"
     ]
    }
   ],
   "source": [
    "## DESIGN B\n",
    "import time \n",
    "start = time.time()\n",
    "historyB = modelB.fit(train_generator, epochs=epochs, validation_data=val_generator, verbose=2, callbacks = [reduce_lr])\n",
    "stop = time.time()\n",
    "print(f\"Training time: {stop - start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/128\n",
      "16/16 - 7s - loss: 63.1768 - mae: 7.8585 - val_loss: 76.0284 - val_mae: 8.6476 - lr: 1.0000e-08 - 7s/epoch - 416ms/step\n",
      "Epoch 2/128\n",
      "16/16 - 1s - loss: 63.0616 - mae: 7.8496 - val_loss: 77.7025 - val_mae: 8.7438 - lr: 1.0000e-08 - 769ms/epoch - 48ms/step\n",
      "Epoch 3/128\n",
      "16/16 - 1s - loss: 63.0752 - mae: 7.8515 - val_loss: 76.2799 - val_mae: 8.6618 - lr: 1.0000e-08 - 764ms/epoch - 48ms/step\n",
      "Epoch 4/128\n",
      "16/16 - 1s - loss: 62.3993 - mae: 7.8095 - val_loss: 73.5383 - val_mae: 8.5020 - lr: 1.0000e-08 - 765ms/epoch - 48ms/step\n",
      "Epoch 5/128\n",
      "16/16 - 1s - loss: 62.6017 - mae: 7.8222 - val_loss: 74.0009 - val_mae: 8.5294 - lr: 1.0000e-08 - 757ms/epoch - 47ms/step\n",
      "Epoch 6/128\n",
      "16/16 - 1s - loss: 61.9092 - mae: 7.7812 - val_loss: 74.8776 - val_mae: 8.5803 - lr: 1.0000e-08 - 762ms/epoch - 48ms/step\n",
      "Epoch 7/128\n",
      "16/16 - 1s - loss: 61.6127 - mae: 7.7592 - val_loss: 80.7843 - val_mae: 8.9179 - lr: 1.0000e-08 - 784ms/epoch - 49ms/step\n",
      "Epoch 8/128\n",
      "16/16 - 1s - loss: 61.1199 - mae: 7.7250 - val_loss: 76.4458 - val_mae: 8.6716 - lr: 1.0000e-08 - 772ms/epoch - 48ms/step\n",
      "Epoch 9/128\n",
      "16/16 - 1s - loss: 60.8319 - mae: 7.7083 - val_loss: 73.7108 - val_mae: 8.5140 - lr: 1.0000e-09 - 762ms/epoch - 48ms/step\n",
      "Epoch 10/128\n",
      "16/16 - 1s - loss: 60.9751 - mae: 7.7203 - val_loss: 68.2280 - val_mae: 8.1862 - lr: 1.0000e-09 - 771ms/epoch - 48ms/step\n",
      "Epoch 11/128\n",
      "16/16 - 1s - loss: 61.0369 - mae: 7.7207 - val_loss: 61.2127 - val_mae: 7.7474 - lr: 1.0000e-09 - 777ms/epoch - 49ms/step\n",
      "Epoch 12/128\n",
      "16/16 - 1s - loss: 60.7628 - mae: 7.7038 - val_loss: 43.8969 - val_mae: 6.5314 - lr: 1.0000e-09 - 774ms/epoch - 48ms/step\n",
      "Epoch 13/128\n",
      "16/16 - 1s - loss: 60.7118 - mae: 7.7029 - val_loss: 33.7563 - val_mae: 5.6926 - lr: 1.0000e-09 - 751ms/epoch - 47ms/step\n",
      "Epoch 14/128\n",
      "16/16 - 1s - loss: 60.9245 - mae: 7.7125 - val_loss: 21.2183 - val_mae: 4.4020 - lr: 1.0000e-09 - 774ms/epoch - 48ms/step\n",
      "Epoch 15/128\n",
      "16/16 - 1s - loss: 60.6346 - mae: 7.6985 - val_loss: 11.0844 - val_mae: 2.9096 - lr: 1.0000e-09 - 764ms/epoch - 48ms/step\n",
      "Epoch 16/128\n",
      "16/16 - 1s - loss: 60.5497 - mae: 7.6902 - val_loss: 3.9870 - val_mae: 1.6515 - lr: 1.0000e-09 - 782ms/epoch - 49ms/step\n",
      "Epoch 17/128\n",
      "16/16 - 1s - loss: 61.0929 - mae: 7.7241 - val_loss: 13.6584 - val_mae: 3.2457 - lr: 1.0000e-09 - 742ms/epoch - 46ms/step\n",
      "Epoch 18/128\n",
      "16/16 - 1s - loss: 60.4160 - mae: 7.6802 - val_loss: 28.0402 - val_mae: 4.8680 - lr: 1.0000e-09 - 762ms/epoch - 48ms/step\n",
      "Epoch 19/128\n",
      "16/16 - 1s - loss: 60.6010 - mae: 7.6979 - val_loss: 40.9007 - val_mae: 5.9102 - lr: 1.0000e-09 - 765ms/epoch - 48ms/step\n",
      "Epoch 20/128\n",
      "16/16 - 1s - loss: 60.6329 - mae: 7.6924 - val_loss: 71.9936 - val_mae: 7.6722 - lr: 1.0000e-09 - 771ms/epoch - 48ms/step\n",
      "Epoch 21/128\n",
      "16/16 - 1s - loss: 60.2713 - mae: 7.6758 - val_loss: 92.0390 - val_mae: 8.6509 - lr: 1.0000e-09 - 772ms/epoch - 48ms/step\n",
      "Epoch 22/128\n",
      "16/16 - 1s - loss: 60.6448 - mae: 7.6956 - val_loss: 103.8002 - val_mae: 9.0355 - lr: 1.0000e-09 - 765ms/epoch - 48ms/step\n",
      "Epoch 23/128\n",
      "16/16 - 1s - loss: 60.6981 - mae: 7.6992 - val_loss: 146.8002 - val_mae: 10.8145 - lr: 1.0000e-09 - 787ms/epoch - 49ms/step\n",
      "Epoch 24/128\n",
      "16/16 - 1s - loss: 60.4097 - mae: 7.6836 - val_loss: 148.0383 - val_mae: 11.0364 - lr: 1.0000e-09 - 776ms/epoch - 48ms/step\n",
      "Epoch 25/128\n",
      "16/16 - 1s - loss: 60.2738 - mae: 7.6725 - val_loss: 177.1063 - val_mae: 12.0376 - lr: 1.0000e-09 - 761ms/epoch - 48ms/step\n",
      "Epoch 26/128\n",
      "16/16 - 1s - loss: 60.2776 - mae: 7.6715 - val_loss: 201.4756 - val_mae: 12.7615 - lr: 1.0000e-09 - 748ms/epoch - 47ms/step\n",
      "Epoch 27/128\n",
      "16/16 - 1s - loss: 59.9365 - mae: 7.6520 - val_loss: 247.3050 - val_mae: 14.4150 - lr: 1.0000e-09 - 749ms/epoch - 47ms/step\n",
      "Epoch 28/128\n",
      "16/16 - 1s - loss: 59.8502 - mae: 7.6476 - val_loss: 233.6531 - val_mae: 14.0295 - lr: 1.0000e-09 - 750ms/epoch - 47ms/step\n",
      "Epoch 29/128\n",
      "16/16 - 1s - loss: 59.7542 - mae: 7.6401 - val_loss: 259.5511 - val_mae: 14.6829 - lr: 1.0000e-09 - 766ms/epoch - 48ms/step\n",
      "Epoch 30/128\n",
      "16/16 - 1s - loss: 60.1487 - mae: 7.6639 - val_loss: 212.4006 - val_mae: 13.0875 - lr: 1.0000e-09 - 760ms/epoch - 48ms/step\n",
      "Epoch 31/128\n",
      "16/16 - 1s - loss: 60.0972 - mae: 7.6637 - val_loss: 201.2759 - val_mae: 12.9221 - lr: 1.0000e-09 - 763ms/epoch - 48ms/step\n",
      "Epoch 32/128\n",
      "16/16 - 1s - loss: 60.1698 - mae: 7.6619 - val_loss: 168.0978 - val_mae: 11.8740 - lr: 1.0000e-09 - 745ms/epoch - 47ms/step\n",
      "Epoch 33/128\n",
      "16/16 - 1s - loss: 60.1210 - mae: 7.6629 - val_loss: 129.5281 - val_mae: 10.6958 - lr: 1.0000e-09 - 736ms/epoch - 46ms/step\n",
      "Epoch 34/128\n",
      "16/16 - 1s - loss: 60.2115 - mae: 7.6691 - val_loss: 112.0657 - val_mae: 10.1509 - lr: 1.0000e-09 - 770ms/epoch - 48ms/step\n",
      "Epoch 35/128\n",
      "16/16 - 1s - loss: 59.5607 - mae: 7.6259 - val_loss: 119.4959 - val_mae: 10.4449 - lr: 1.0000e-09 - 760ms/epoch - 47ms/step\n",
      "Epoch 36/128\n",
      "16/16 - 1s - loss: 60.3767 - mae: 7.6789 - val_loss: 96.2214 - val_mae: 9.2948 - lr: 1.0000e-09 - 766ms/epoch - 48ms/step\n",
      "Epoch 37/128\n",
      "16/16 - 1s - loss: 60.0086 - mae: 7.6587 - val_loss: 77.4943 - val_mae: 8.1690 - lr: 1.0000e-09 - 752ms/epoch - 47ms/step\n",
      "Epoch 38/128\n",
      "16/16 - 1s - loss: 60.2274 - mae: 7.6712 - val_loss: 73.9557 - val_mae: 7.7412 - lr: 1.0000e-09 - 763ms/epoch - 48ms/step\n",
      "Epoch 39/128\n",
      "16/16 - 1s - loss: 59.9756 - mae: 7.6505 - val_loss: 55.1672 - val_mae: 6.3235 - lr: 1.0000e-09 - 747ms/epoch - 47ms/step\n",
      "Epoch 40/128\n",
      "16/16 - 1s - loss: 59.9281 - mae: 7.6538 - val_loss: 30.8786 - val_mae: 4.3104 - lr: 1.0000e-09 - 759ms/epoch - 47ms/step\n",
      "Epoch 41/128\n",
      "16/16 - 1s - loss: 59.6960 - mae: 7.6357 - val_loss: 22.4213 - val_mae: 3.7509 - lr: 1.0000e-09 - 758ms/epoch - 47ms/step\n",
      "Epoch 42/128\n",
      "16/16 - 1s - loss: 59.8267 - mae: 7.6434 - val_loss: 18.1844 - val_mae: 3.5163 - lr: 1.0000e-09 - 769ms/epoch - 48ms/step\n",
      "Epoch 43/128\n",
      "16/16 - 1s - loss: 59.4658 - mae: 7.6178 - val_loss: 17.8504 - val_mae: 3.6615 - lr: 1.0000e-09 - 751ms/epoch - 47ms/step\n",
      "Epoch 44/128\n",
      "16/16 - 1s - loss: 59.5566 - mae: 7.6270 - val_loss: 22.7052 - val_mae: 4.2104 - lr: 1.0000e-09 - 778ms/epoch - 49ms/step\n",
      "Epoch 45/128\n",
      "16/16 - 1s - loss: 59.6375 - mae: 7.6332 - val_loss: 28.3180 - val_mae: 4.7326 - lr: 1.0000e-09 - 764ms/epoch - 48ms/step\n",
      "Epoch 46/128\n",
      "16/16 - 1s - loss: 59.7495 - mae: 7.6413 - val_loss: 33.1071 - val_mae: 5.2572 - lr: 1.0000e-09 - 748ms/epoch - 47ms/step\n",
      "Epoch 47/128\n",
      "16/16 - 1s - loss: 59.5979 - mae: 7.6279 - val_loss: 37.0130 - val_mae: 5.6809 - lr: 1.0000e-09 - 751ms/epoch - 47ms/step\n",
      "Epoch 48/128\n",
      "16/16 - 1s - loss: 59.4792 - mae: 7.6207 - val_loss: 40.3588 - val_mae: 6.0469 - lr: 1.0000e-09 - 772ms/epoch - 48ms/step\n",
      "Epoch 49/128\n",
      "16/16 - 1s - loss: 59.3917 - mae: 7.6150 - val_loss: 43.8461 - val_mae: 6.3533 - lr: 1.0000e-09 - 763ms/epoch - 48ms/step\n",
      "Epoch 50/128\n",
      "16/16 - 1s - loss: 59.7895 - mae: 7.6410 - val_loss: 47.5843 - val_mae: 6.6782 - lr: 1.0000e-09 - 759ms/epoch - 47ms/step\n",
      "Epoch 51/128\n",
      "16/16 - 1s - loss: 59.5440 - mae: 7.6215 - val_loss: 51.6818 - val_mae: 6.9899 - lr: 1.0000e-09 - 748ms/epoch - 47ms/step\n",
      "Epoch 52/128\n",
      "16/16 - 1s - loss: 59.3794 - mae: 7.6167 - val_loss: 53.7154 - val_mae: 7.1369 - lr: 1.0000e-09 - 736ms/epoch - 46ms/step\n",
      "Epoch 53/128\n",
      "16/16 - 1s - loss: 59.3092 - mae: 7.6112 - val_loss: 53.4781 - val_mae: 7.1462 - lr: 1.0000e-09 - 748ms/epoch - 47ms/step\n",
      "Epoch 54/128\n",
      "16/16 - 1s - loss: 59.4677 - mae: 7.6167 - val_loss: 53.2337 - val_mae: 7.1481 - lr: 1.0000e-09 - 769ms/epoch - 48ms/step\n",
      "Epoch 55/128\n",
      "16/16 - 1s - loss: 59.8092 - mae: 7.6443 - val_loss: 54.0290 - val_mae: 7.2170 - lr: 1.0000e-09 - 766ms/epoch - 48ms/step\n",
      "Epoch 56/128\n",
      "16/16 - 1s - loss: 59.1888 - mae: 7.6005 - val_loss: 54.9618 - val_mae: 7.2915 - lr: 1.0000e-09 - 732ms/epoch - 46ms/step\n",
      "Epoch 57/128\n",
      "16/16 - 1s - loss: 59.3795 - mae: 7.6160 - val_loss: 55.9010 - val_mae: 7.3606 - lr: 1.0000e-09 - 783ms/epoch - 49ms/step\n",
      "Epoch 58/128\n",
      "16/16 - 1s - loss: 59.3575 - mae: 7.6145 - val_loss: 55.9157 - val_mae: 7.3570 - lr: 1.0000e-09 - 798ms/epoch - 50ms/step\n",
      "Epoch 59/128\n",
      "16/16 - 1s - loss: 59.2997 - mae: 7.6072 - val_loss: 56.4105 - val_mae: 7.3927 - lr: 1.0000e-09 - 782ms/epoch - 49ms/step\n",
      "Epoch 60/128\n",
      "16/16 - 1s - loss: 59.2514 - mae: 7.6046 - val_loss: 57.0266 - val_mae: 7.4417 - lr: 1.0000e-09 - 771ms/epoch - 48ms/step\n",
      "Epoch 61/128\n",
      "16/16 - 1s - loss: 59.3765 - mae: 7.6137 - val_loss: 57.0048 - val_mae: 7.4510 - lr: 1.0000e-09 - 794ms/epoch - 50ms/step\n",
      "Epoch 62/128\n",
      "16/16 - 1s - loss: 58.8488 - mae: 7.5826 - val_loss: 56.8790 - val_mae: 7.4428 - lr: 1.0000e-09 - 751ms/epoch - 47ms/step\n",
      "Epoch 63/128\n",
      "16/16 - 1s - loss: 59.3726 - mae: 7.6115 - val_loss: 56.8471 - val_mae: 7.4458 - lr: 1.0000e-09 - 780ms/epoch - 49ms/step\n",
      "Epoch 64/128\n",
      "16/16 - 1s - loss: 59.0126 - mae: 7.5869 - val_loss: 56.9366 - val_mae: 7.4534 - lr: 1.0000e-09 - 769ms/epoch - 48ms/step\n",
      "Epoch 65/128\n",
      "16/16 - 1s - loss: 59.1902 - mae: 7.6026 - val_loss: 57.2468 - val_mae: 7.4731 - lr: 1.0000e-09 - 772ms/epoch - 48ms/step\n",
      "Epoch 66/128\n",
      "16/16 - 1s - loss: 59.2919 - mae: 7.6065 - val_loss: 57.2603 - val_mae: 7.4743 - lr: 1.0000e-09 - 760ms/epoch - 48ms/step\n",
      "Epoch 67/128\n",
      "16/16 - 1s - loss: 58.9111 - mae: 7.5874 - val_loss: 57.3326 - val_mae: 7.4801 - lr: 1.0000e-09 - 736ms/epoch - 46ms/step\n",
      "Epoch 68/128\n",
      "16/16 - 1s - loss: 59.0950 - mae: 7.5951 - val_loss: 57.3554 - val_mae: 7.4853 - lr: 1.0000e-09 - 758ms/epoch - 47ms/step\n",
      "Epoch 69/128\n",
      "16/16 - 1s - loss: 59.0323 - mae: 7.5888 - val_loss: 57.4112 - val_mae: 7.4877 - lr: 1.0000e-09 - 772ms/epoch - 48ms/step\n",
      "Epoch 70/128\n",
      "16/16 - 1s - loss: 58.7077 - mae: 7.5685 - val_loss: 57.4065 - val_mae: 7.4869 - lr: 1.0000e-09 - 763ms/epoch - 48ms/step\n",
      "Epoch 71/128\n",
      "16/16 - 1s - loss: 59.0555 - mae: 7.5908 - val_loss: 57.3738 - val_mae: 7.4837 - lr: 1.0000e-09 - 761ms/epoch - 48ms/step\n",
      "Epoch 72/128\n",
      "16/16 - 1s - loss: 58.8071 - mae: 7.5726 - val_loss: 57.2949 - val_mae: 7.4800 - lr: 1.0000e-09 - 760ms/epoch - 48ms/step\n",
      "Epoch 73/128\n",
      "16/16 - 1s - loss: 59.0159 - mae: 7.5955 - val_loss: 57.2098 - val_mae: 7.4737 - lr: 1.0000e-09 - 750ms/epoch - 47ms/step\n",
      "Epoch 74/128\n",
      "16/16 - 1s - loss: 58.7649 - mae: 7.5736 - val_loss: 57.2780 - val_mae: 7.4793 - lr: 1.0000e-09 - 755ms/epoch - 47ms/step\n",
      "Epoch 75/128\n",
      "16/16 - 1s - loss: 58.7774 - mae: 7.5729 - val_loss: 57.4230 - val_mae: 7.4894 - lr: 1.0000e-09 - 772ms/epoch - 48ms/step\n",
      "Epoch 76/128\n",
      "16/16 - 1s - loss: 58.7207 - mae: 7.5690 - val_loss: 57.4693 - val_mae: 7.4932 - lr: 1.0000e-09 - 777ms/epoch - 49ms/step\n",
      "Epoch 77/128\n",
      "16/16 - 1s - loss: 58.6333 - mae: 7.5626 - val_loss: 57.4277 - val_mae: 7.4906 - lr: 1.0000e-09 - 773ms/epoch - 48ms/step\n",
      "Epoch 78/128\n",
      "16/16 - 1s - loss: 58.9250 - mae: 7.5814 - val_loss: 57.2848 - val_mae: 7.4840 - lr: 1.0000e-09 - 770ms/epoch - 48ms/step\n",
      "Epoch 79/128\n",
      "16/16 - 1s - loss: 58.4813 - mae: 7.5561 - val_loss: 57.3345 - val_mae: 7.4879 - lr: 1.0000e-09 - 771ms/epoch - 48ms/step\n",
      "Epoch 80/128\n",
      "16/16 - 1s - loss: 58.1070 - mae: 7.5326 - val_loss: 57.3459 - val_mae: 7.4889 - lr: 1.0000e-09 - 798ms/epoch - 50ms/step\n",
      "Epoch 81/128\n",
      "16/16 - 1s - loss: 58.6874 - mae: 7.5676 - val_loss: 57.3349 - val_mae: 7.4888 - lr: 1.0000e-09 - 792ms/epoch - 50ms/step\n",
      "Epoch 82/128\n",
      "16/16 - 1s - loss: 58.3198 - mae: 7.5462 - val_loss: 57.3050 - val_mae: 7.4879 - lr: 1.0000e-09 - 778ms/epoch - 49ms/step\n",
      "Epoch 83/128\n",
      "16/16 - 1s - loss: 58.2407 - mae: 7.5416 - val_loss: 57.4060 - val_mae: 7.4954 - lr: 1.0000e-09 - 772ms/epoch - 48ms/step\n",
      "Epoch 84/128\n",
      "16/16 - 1s - loss: 58.1498 - mae: 7.5342 - val_loss: 57.3741 - val_mae: 7.4926 - lr: 1.0000e-09 - 788ms/epoch - 49ms/step\n",
      "Epoch 85/128\n",
      "16/16 - 1s - loss: 58.3803 - mae: 7.5466 - val_loss: 57.2528 - val_mae: 7.4839 - lr: 1.0000e-09 - 824ms/epoch - 51ms/step\n",
      "Epoch 86/128\n",
      "16/16 - 1s - loss: 58.3643 - mae: 7.5471 - val_loss: 57.2553 - val_mae: 7.4840 - lr: 1.0000e-09 - 748ms/epoch - 47ms/step\n",
      "Epoch 87/128\n",
      "16/16 - 1s - loss: 57.9903 - mae: 7.5236 - val_loss: 57.1569 - val_mae: 7.4778 - lr: 1.0000e-09 - 755ms/epoch - 47ms/step\n",
      "Epoch 88/128\n",
      "16/16 - 1s - loss: 58.1752 - mae: 7.5359 - val_loss: 57.1158 - val_mae: 7.4744 - lr: 1.0000e-09 - 760ms/epoch - 47ms/step\n",
      "Epoch 89/128\n",
      "16/16 - 1s - loss: 58.3716 - mae: 7.5475 - val_loss: 57.0759 - val_mae: 7.4714 - lr: 1.0000e-09 - 769ms/epoch - 48ms/step\n",
      "Epoch 90/128\n",
      "16/16 - 1s - loss: 58.3785 - mae: 7.5475 - val_loss: 57.0528 - val_mae: 7.4700 - lr: 1.0000e-09 - 748ms/epoch - 47ms/step\n",
      "Epoch 91/128\n",
      "16/16 - 1s - loss: 58.2099 - mae: 7.5403 - val_loss: 56.9787 - val_mae: 7.4648 - lr: 1.0000e-09 - 758ms/epoch - 47ms/step\n",
      "Epoch 92/128\n",
      "16/16 - 1s - loss: 58.4365 - mae: 7.5546 - val_loss: 57.0764 - val_mae: 7.4709 - lr: 1.0000e-09 - 790ms/epoch - 49ms/step\n",
      "Epoch 93/128\n",
      "16/16 - 1s - loss: 58.1808 - mae: 7.5340 - val_loss: 57.0544 - val_mae: 7.4691 - lr: 1.0000e-09 - 748ms/epoch - 47ms/step\n",
      "Epoch 94/128\n",
      "16/16 - 1s - loss: 58.0195 - mae: 7.5232 - val_loss: 57.0162 - val_mae: 7.4662 - lr: 1.0000e-09 - 740ms/epoch - 46ms/step\n",
      "Epoch 95/128\n",
      "16/16 - 1s - loss: 58.2046 - mae: 7.5370 - val_loss: 56.9583 - val_mae: 7.4618 - lr: 1.0000e-09 - 750ms/epoch - 47ms/step\n",
      "Epoch 96/128\n",
      "16/16 - 1s - loss: 57.9900 - mae: 7.5206 - val_loss: 56.9435 - val_mae: 7.4608 - lr: 1.0000e-09 - 763ms/epoch - 48ms/step\n",
      "Epoch 97/128\n",
      "16/16 - 1s - loss: 58.0522 - mae: 7.5247 - val_loss: 56.9374 - val_mae: 7.4599 - lr: 1.0000e-09 - 752ms/epoch - 47ms/step\n",
      "Epoch 98/128\n",
      "16/16 - 1s - loss: 57.7424 - mae: 7.5074 - val_loss: 56.8889 - val_mae: 7.4569 - lr: 1.0000e-09 - 731ms/epoch - 46ms/step\n",
      "Epoch 99/128\n",
      "16/16 - 1s - loss: 58.5151 - mae: 7.5568 - val_loss: 56.8546 - val_mae: 7.4544 - lr: 1.0000e-09 - 769ms/epoch - 48ms/step\n",
      "Epoch 100/128\n",
      "16/16 - 1s - loss: 57.6790 - mae: 7.5044 - val_loss: 56.7489 - val_mae: 7.4472 - lr: 1.0000e-09 - 749ms/epoch - 47ms/step\n",
      "Epoch 101/128\n",
      "16/16 - 1s - loss: 57.7665 - mae: 7.5104 - val_loss: 56.7384 - val_mae: 7.4467 - lr: 1.0000e-09 - 751ms/epoch - 47ms/step\n",
      "Epoch 102/128\n",
      "16/16 - 1s - loss: 57.7231 - mae: 7.5041 - val_loss: 56.6913 - val_mae: 7.4433 - lr: 1.0000e-09 - 736ms/epoch - 46ms/step\n",
      "Epoch 103/128\n",
      "16/16 - 1s - loss: 57.7963 - mae: 7.5146 - val_loss: 56.6720 - val_mae: 7.4416 - lr: 1.0000e-09 - 756ms/epoch - 47ms/step\n",
      "Epoch 104/128\n",
      "16/16 - 1s - loss: 57.9466 - mae: 7.5209 - val_loss: 56.6419 - val_mae: 7.4397 - lr: 1.0000e-09 - 736ms/epoch - 46ms/step\n",
      "Epoch 105/128\n",
      "16/16 - 1s - loss: 57.9365 - mae: 7.5196 - val_loss: 56.6258 - val_mae: 7.4387 - lr: 1.0000e-09 - 751ms/epoch - 47ms/step\n",
      "Epoch 106/128\n",
      "16/16 - 1s - loss: 57.4767 - mae: 7.4884 - val_loss: 56.5599 - val_mae: 7.4343 - lr: 1.0000e-09 - 761ms/epoch - 48ms/step\n",
      "Epoch 107/128\n",
      "16/16 - 1s - loss: 57.4007 - mae: 7.4857 - val_loss: 56.5750 - val_mae: 7.4356 - lr: 1.0000e-09 - 807ms/epoch - 50ms/step\n",
      "Epoch 108/128\n",
      "16/16 - 1s - loss: 57.9845 - mae: 7.5143 - val_loss: 56.4811 - val_mae: 7.4291 - lr: 1.0000e-09 - 761ms/epoch - 48ms/step\n",
      "Epoch 109/128\n",
      "16/16 - 1s - loss: 57.6347 - mae: 7.5003 - val_loss: 56.4715 - val_mae: 7.4287 - lr: 1.0000e-09 - 745ms/epoch - 47ms/step\n",
      "Epoch 110/128\n",
      "16/16 - 1s - loss: 57.8373 - mae: 7.5120 - val_loss: 56.4302 - val_mae: 7.4251 - lr: 1.0000e-09 - 746ms/epoch - 47ms/step\n",
      "Epoch 111/128\n",
      "16/16 - 1s - loss: 57.4805 - mae: 7.4938 - val_loss: 56.4893 - val_mae: 7.4293 - lr: 1.0000e-09 - 768ms/epoch - 48ms/step\n",
      "Epoch 112/128\n",
      "16/16 - 1s - loss: 57.3397 - mae: 7.4830 - val_loss: 56.3979 - val_mae: 7.4231 - lr: 1.0000e-09 - 764ms/epoch - 48ms/step\n",
      "Epoch 113/128\n",
      "16/16 - 1s - loss: 57.4576 - mae: 7.4902 - val_loss: 56.2886 - val_mae: 7.4155 - lr: 1.0000e-09 - 740ms/epoch - 46ms/step\n",
      "Epoch 114/128\n",
      "16/16 - 1s - loss: 57.1448 - mae: 7.4656 - val_loss: 56.1588 - val_mae: 7.4063 - lr: 1.0000e-09 - 752ms/epoch - 47ms/step\n",
      "Epoch 115/128\n",
      "16/16 - 1s - loss: 57.5318 - mae: 7.4901 - val_loss: 56.1390 - val_mae: 7.4055 - lr: 1.0000e-09 - 749ms/epoch - 47ms/step\n",
      "Epoch 116/128\n",
      "16/16 - 1s - loss: 57.4997 - mae: 7.4886 - val_loss: 56.1785 - val_mae: 7.4079 - lr: 1.0000e-09 - 736ms/epoch - 46ms/step\n",
      "Epoch 117/128\n",
      "16/16 - 1s - loss: 57.5252 - mae: 7.4936 - val_loss: 56.1133 - val_mae: 7.4042 - lr: 1.0000e-09 - 750ms/epoch - 47ms/step\n",
      "Epoch 118/128\n",
      "16/16 - 1s - loss: 57.5565 - mae: 7.4914 - val_loss: 56.0247 - val_mae: 7.3977 - lr: 1.0000e-09 - 761ms/epoch - 48ms/step\n",
      "Epoch 119/128\n",
      "16/16 - 1s - loss: 57.0583 - mae: 7.4601 - val_loss: 55.9705 - val_mae: 7.3931 - lr: 1.0000e-09 - 735ms/epoch - 46ms/step\n",
      "Epoch 120/128\n",
      "16/16 - 1s - loss: 57.1992 - mae: 7.4697 - val_loss: 55.9499 - val_mae: 7.3910 - lr: 1.0000e-09 - 752ms/epoch - 47ms/step\n",
      "Epoch 121/128\n",
      "16/16 - 1s - loss: 57.1751 - mae: 7.4658 - val_loss: 55.9478 - val_mae: 7.3916 - lr: 1.0000e-09 - 748ms/epoch - 47ms/step\n",
      "Epoch 122/128\n",
      "16/16 - 1s - loss: 56.7661 - mae: 7.4398 - val_loss: 55.8668 - val_mae: 7.3852 - lr: 1.0000e-09 - 754ms/epoch - 47ms/step\n",
      "Epoch 123/128\n",
      "16/16 - 1s - loss: 57.4119 - mae: 7.4874 - val_loss: 55.8291 - val_mae: 7.3824 - lr: 1.0000e-09 - 750ms/epoch - 47ms/step\n",
      "Epoch 124/128\n",
      "16/16 - 1s - loss: 57.4318 - mae: 7.4825 - val_loss: 55.8135 - val_mae: 7.3817 - lr: 1.0000e-09 - 741ms/epoch - 46ms/step\n",
      "Epoch 125/128\n",
      "16/16 - 1s - loss: 56.9261 - mae: 7.4562 - val_loss: 55.8557 - val_mae: 7.3856 - lr: 1.0000e-09 - 768ms/epoch - 48ms/step\n",
      "Epoch 126/128\n",
      "16/16 - 1s - loss: 57.4879 - mae: 7.4833 - val_loss: 55.8815 - val_mae: 7.3881 - lr: 1.0000e-09 - 760ms/epoch - 48ms/step\n",
      "Epoch 127/128\n",
      "16/16 - 1s - loss: 57.1275 - mae: 7.4636 - val_loss: 55.8584 - val_mae: 7.3864 - lr: 1.0000e-09 - 768ms/epoch - 48ms/step\n",
      "Epoch 128/128\n",
      "16/16 - 1s - loss: 56.9397 - mae: 7.4526 - val_loss: 55.7862 - val_mae: 7.3814 - lr: 1.0000e-09 - 745ms/epoch - 47ms/step\n",
      "Training time: 105.09599757194519s\n"
     ]
    }
   ],
   "source": [
    "## DESIGN C\n",
    "import time \n",
    "start = time.time()\n",
    "historyC = modelC.fit(train_generator, epochs=epochs, validation_data=val_generator, verbose=2, callbacks = [reduce_lr])\n",
    "stop = time.time()\n",
    "print(f\"Training time: {stop - start}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ECONOMIC: FLOATING-POINT OPERATIONS PER SECOND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLOPS: 2188501525\n"
     ]
    }
   ],
   "source": [
    "## Design A\n",
    "## ECONOMIC: FLOATING-POINT OPERATIONS PER SECOND\n",
    "# Calculae FLOPS\n",
    "from keras_flops import get_flops\n",
    "flopsA = get_flops(modelA, batch_size=1)\n",
    "print(f\"FLOPS: {flopsA}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLOPS: 353032971\n"
     ]
    }
   ],
   "source": [
    "## Design B\n",
    "## ECONOMIC: FLOATING-POINT OPERATIONS PER SECOND\n",
    "# Calculae FLOPS\n",
    "from keras_flops import get_flops\n",
    "flopsB = get_flops(modelB, batch_size=1)\n",
    "print(f\"FLOPS: {flopsB}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLOPS: 824909063\n"
     ]
    }
   ],
   "source": [
    "## Design C\n",
    "## ECONOMIC: FLOATING-POINT OPERATIONS PER SECOND\n",
    "# Calculae FLOPS\n",
    "from keras_flops import get_flops\n",
    "flopsC = get_flops(modelC, batch_size=1)\n",
    "print(f\"FLOPS: {flopsC}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FUNCTIONALITY: INFERENCE TIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_sample = train_generator[1][0][0].reshape(1,32,32,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n",
      "Inference time: 83.0002ms\n"
     ]
    }
   ],
   "source": [
    "## Design A\n",
    "## FUNCTIONALITY: INFERENCE TIME\n",
    "start = time.time()\n",
    "modelA.predict(inference_sample)\n",
    "stop = time.time()\n",
    "print(f\"Inference time: {(stop - start)*1e3:.4f}ms\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 41ms/step\n",
      "Inference time: 88.9966ms\n"
     ]
    }
   ],
   "source": [
    "## Design B\n",
    "## FUNCTIONALITY: INFERENCE TIME\n",
    "start = time.time()\n",
    "modelB.predict(inference_sample)\n",
    "stop = time.time()\n",
    "print(f\"Inference time: {(stop - start)*1e3:.4f}ms\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n",
      "Inference time: 82.0053ms\n"
     ]
    }
   ],
   "source": [
    "## Design AC\n",
    "## FUNCTIONALITY: INFERENCE TIME\n",
    "start = time.time()\n",
    "modelC.predict(inference_sample)\n",
    "stop = time.time()\n",
    "print(f\"Inference time: {(stop - start)*1e3:.4f}ms\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PERFORMANCE: COEFFICIENT OF DETERMINATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prepare set of x values and y values for performance constraint\n",
    "X_values,y_values = [],[]\n",
    "for i in range(100):\n",
    "    values = next(train_generator)\n",
    "    # for j in range(values[0].shape[0]):\n",
    "    X_values.append(values[0])\n",
    "    y_values.append(values[1])\n",
    "\n",
    "## create X_values generator\n",
    "gen_X_values_1 = (x for x in X_values)\n",
    "gen_X_values_2 = (x for x in X_values)\n",
    "gen_X_values_3 = (x for x in X_values)\n",
    "y_values = [y  for y_set in y_values for y in y_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 2s 24ms/step\n",
      "-38.0581\n"
     ]
    }
   ],
   "source": [
    "## Design A\n",
    "## PERFORMANCE: COEFFICIENT OF DETERMINATION\n",
    "from sklearn.metrics import r2_score\n",
    "predictionsA = modelA.predict(gen_X_values_1)#.reshape(3200)\n",
    "codA = r2_score(y_values,predictionsA)\n",
    "print(f'{codA:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 1s 9ms/step\n",
      "-0.0924\n"
     ]
    }
   ],
   "source": [
    "## Design B\n",
    "## PERFORMANCE: COEFFICIENT OF DETERMINATION\n",
    "from sklearn.metrics import r2_score\n",
    "predictionsB = modelB.predict(gen_X_values_2)#.reshape(3200)\n",
    "codB = r2_score(y_values,predictionsB)\n",
    "print(f'{codB:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      1/Unknown - 0s 28ms/step"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 1s 12ms/step\n",
      "-44.4278\n"
     ]
    }
   ],
   "source": [
    "## Design C\n",
    "## PERFORMANCE: COEFFICIENT OF DETERMINATION\n",
    "from sklearn.metrics import r2_score\n",
    "predictionsC = modelC.predict(gen_X_values_3)#.reshape(1600)\n",
    "codC = r2_score(y_values,predictionsC)\n",
    "print(f'{codC:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EFFICIENCY: STORAGE CONSUMPTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total model weight size in megabytes: 669.7216\n"
     ]
    }
   ],
   "source": [
    "## EFFICIENCY: STORAGE CONSUMPTION\n",
    "weightsA = modelA.get_weights()\n",
    "total_sizeA = 0\n",
    "for weight in weightsA:\n",
    "    total_sizeA += tf.size(weight).numpy()\n",
    "\n",
    "print(f\"Total model weight size in megabytes: {total_sizeA*8e-6:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total model weight size in megabytes: 535.5884\n"
     ]
    }
   ],
   "source": [
    "## EFFICIENCY: STORAGE CONSUMPTION\n",
    "weightsB = modelB.get_weights()\n",
    "total_sizeB = 0\n",
    "for weight in weightsB:\n",
    "    total_sizeB += tf.size(weight).numpy()\n",
    "\n",
    "print(f\"Total model weight size in megabytes: {total_sizeB*8e-6:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.368568125"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_sizeB/(8e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total model weight size in megabytes: 359.2018\n"
     ]
    }
   ],
   "source": [
    "## EFFICIENCY: STORAGE CONSUMPTION\n",
    "weightsC = modelC.get_weights()\n",
    "total_sizeC = 0\n",
    "for weight in weightsC:\n",
    "    total_sizeC += tf.size(weight).numpy()\n",
    "\n",
    "print(f\"Total model weight size in megabytes: {total_sizeC*8e-6:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving final trained and constrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelA.save('design_models/designA_v2.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelB.save('design_models/designB_v2.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelC.save('design_models/designC_v2.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
